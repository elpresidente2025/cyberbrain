import re
import json
import logging
from typing import List, Dict, Any, Optional

logger = logging.getLogger(__name__)

from ..base_agent import Agent
from services.posts.validation import count_keyword_coverage, validate_keyword_insertion

class KeywordInjectorAgent(Agent):
    def __init__(self, name: str = 'KeywordInjectorAgent', options: Optional[Dict[str, Any]] = None):
        super().__init__(name, options)
        from ..common.gemini_client import get_client, DEFAULT_MODEL
        self._client = get_client()
        self.model_name = DEFAULT_MODEL

    def get_min_target(self, keyword_count: int) -> int:
        """ê²€ì¦ ê·œì¹™ê³¼ ë™ì¼í•œ ì‚¬ìš©ì í‚¤ì›Œë“œ ìµœì†Œ ë“±ì¥ íšŸìˆ˜."""
        return 3 if keyword_count >= 2 else 5

    def _extract_keyword_counts(self, keyword_result: Dict[str, Any], keywords: List[str]) -> Dict[str, int]:
        details = (keyword_result.get('details') or {}).get('keywords') or {}
        counts: Dict[str, int] = {}
        for kw in keywords:
            info = details.get(kw) or {}
            counts[kw] = int(info.get('coverage') or info.get('count') or 0)
        return counts

    def _build_keyword_feedback(self, keyword_result: Dict[str, Any], extra_feedback: str = '') -> str:
        details = (keyword_result.get('details') or {}).get('keywords') or {}
        issues: List[str] = []
        for keyword, info in details.items():
            if not isinstance(info, dict):
                continue
            current = int(info.get('coverage') or info.get('count') or 0)
            expected = int(info.get('expected') or 0)
            max_allowed = int(info.get('max') or 9999)
            if current < expected:
                issues.append(f"\"{keyword}\" ë¶€ì¡±: {current}/{expected}")
            elif current > max_allowed:
                issues.append(f"\"{keyword}\" ê³¼ë‹¤: {current}/{max_allowed}")
        if extra_feedback:
            issues.append(extra_feedback)
        return ", ".join(issues) if issues else "í‚¤ì›Œë“œ ê¸°ì¤€ì— ë§ê²Œ ì¡°ì •í•˜ì„¸ìš”."

    async def process(self, context: Dict[str, Any]) -> Dict[str, Any]:
        previous_results = context.get('previousResults', {})

        # ğŸ”§ í‚¤ì›Œë“œ fallback
        user_keywords = (
            context.get('userKeywords') or
            context.get('keywords') or
            context.get('searchKeywords') or
            []
        )
        if isinstance(user_keywords, str):
            user_keywords = [user_keywords] if user_keywords.strip() else []
        auto_keywords = context.get('autoKeywords') or []
        if not isinstance(auto_keywords, list):
            auto_keywords = []
        target_word_count = context.get('targetWordCount')

        structure_result = previous_results.get('StructureAgent', {})
        content = structure_result.get('content') if structure_result else None

        if not content:
            content = context.get('content')
            if not content:
                raise ValueError('Content not found in context or previousResults')

        title = structure_result.get('title') or context.get('title', '')
        source_text = context.get('sourceText', '')
        context_analysis = structure_result.get('contextAnalysis')

        if not user_keywords:
            print('â­ï¸ [KeywordInjectorAgent] ê²€ìƒ‰ì–´ ì—†ìŒ - ìŠ¤í‚µ')
            return {'content': content, 'title': title, 'keywordCounts': {}}

        # Parse Sections
        sections = self.parse_sections(content)
        print(f"ğŸ“Š [KeywordInjectorAgent] ì„¹ì…˜ {len(sections)}ê°œ íŒŒì‹± ì™„ë£Œ")

        # ìµœì†Œ ì‚½ì… ëª©í‘œ ê³„ì‚°
        min_target = self.get_min_target(len(user_keywords))
        max_target = min_target + 1
        print(f"ğŸ“Š [KeywordInjectorAgent] í‚¤ì›Œë“œ ëª©í‘œ: {min_target}~{max_target}íšŒ")

        section_counts = self.count_keywords_per_section(sections, user_keywords)
        initial_keyword_result = validate_keyword_insertion(
            content,
            user_keywords,
            auto_keywords,
            target_word_count,
        )
        total_counts = self._extract_keyword_counts(initial_keyword_result, user_keywords)

        print(f"ğŸ“Š [KeywordInjectorAgent] ì´ˆê¸° ìƒíƒœ: sections={len(sections)}, totalCounts={total_counts}")

        # Validation Check (ê²€ì¦ ëª¨ë“ˆê³¼ ë™ì¼ ê¸°ì¤€)
        validation = self.validate_section_balance(
            section_counts,
            user_keywords,
            min_target=min_target,
            max_target=max_target,
            auto_keywords=auto_keywords,
        )
        if initial_keyword_result.get('valid') and validation['passed']:
            print('âœ… [KeywordInjectorAgent] ì´ˆê¸° ìƒíƒœë¶€í„° í‚¤ì›Œë“œ ì™„ë²½ ê· í˜•')
            return {'content': content, 'title': title, 'keywordCounts': total_counts}

        # Retry Loop
        max_retries = 2
        attempt = 0
        current_content = content
        feedback = self._build_keyword_feedback(initial_keyword_result, validation.get('feedback', ''))

        while attempt <= max_retries:
            attempt += 1
            print(f"ğŸ”„ [KeywordInjectorAgent] ì‹œë„ {attempt}/{max_retries + 1}")

            prompt = self.build_prompt({
                'sections': sections,
                'userKeywords': user_keywords,
                'sectionCounts': section_counts,
                'feedback': feedback,
                'contextAnalysis': context_analysis,
                'minTarget': min_target,
                'maxTarget': max_target,
            })

            # Logging prompt length only
            print(f"ğŸ“ [KeywordInjectorAgent] í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ ({len(prompt)}ì)")

            try:
                from ..common.gemini_client import generate_content_async
                response_text = await generate_content_async(
                    prompt,
                    model_name=self.model_name,
                    # Temperature Lowered: 0.3 for precision and less hallucination
                    temperature=0.3,
                    max_output_tokens=4000,
                    response_mime_type='application/json'
                )

                instructions = self.parse_instructions(response_text)

                if not instructions:
                    print('âš ï¸ [KeywordInjectorAgent] ìœ íš¨í•œ ì§€ì‹œ ì—†ìŒ - ì¬ì‹œë„')
                    feedback = 'ìœ íš¨í•œ ì‚½ì…/ì‚­ì œ ì§€ì‹œê°€ ì—†ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.'
                    continue

                print(f"ğŸ“‹ [KeywordInjectorAgent] {len(instructions)}ê°œ ì§€ì‹œ íŒŒì‹±ë¨")

                current_content = self.apply_instructions(current_content, sections, instructions)

                # Re-parse and validate
                new_sections = self.parse_sections(current_content)
                new_section_counts = self.count_keywords_per_section(new_sections, user_keywords)
                new_keyword_result = validate_keyword_insertion(
                    current_content,
                    user_keywords,
                    auto_keywords,
                    target_word_count,
                )
                new_total_counts = self._extract_keyword_counts(new_keyword_result, user_keywords)
                validation = self.validate_section_balance(
                    new_section_counts,
                    user_keywords,
                    min_target=min_target,
                    max_target=max_target,
                    auto_keywords=auto_keywords,
                )

                if new_keyword_result.get('valid') and validation['passed']:
                    print(f"âœ… [KeywordInjectorAgent] í‚¤ì›Œë“œ ê· í˜• ë‹¬ì„±: {new_total_counts}")
                    return {
                        'content': current_content,
                        'title': title,
                        'keywordCounts': new_total_counts
                    }

                feedback = self._build_keyword_feedback(new_keyword_result, validation.get('feedback', ''))
                print(f"âš ï¸ [KeywordInjectorAgent] ê²€ì¦ ì‹¤íŒ¨: {feedback}")

                if attempt > max_retries:
                    print('â›” [KeywordInjectorAgent] ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼ - í˜„ì¬ ê²°ê³¼ ë°˜í™˜')
                    return {
                        'content': current_content,
                        'title': title,
                        'keywordCounts': new_total_counts
                    }

                # Update loop state (best effort chain)
                content = current_content
                sections = new_sections
                section_counts = new_section_counts

            except Exception as e:
                print(f"âŒ [KeywordInjectorAgent] ì—ëŸ¬ ë°œìƒ: {str(e)}")
                feedback = str(e)
                if attempt > max_retries:
                    return {'content': current_content, 'title': title, 'keywordCounts': {}}

        return {'content': content, 'title': title, 'keywordCounts': total_counts}

    def parse_sections(self, content: str) -> List[Dict]:
        sections = []
        h2_iter = list(re.finditer(r'<h2[^>]*>[\s\S]*?<\/h2>', content, re.IGNORECASE))
        
        if not h2_iter:
            sections.append({
                'type': 'single',
                'startIndex': 0,
                'endIndex': len(content),
                'content': content
            })
            return sections
            
        first_h2_start = h2_iter[0].start()
        if first_h2_start > 0:
            sections.append({
                'type': 'intro',
                'startIndex': 0,
                'endIndex': first_h2_start,
                'content': content[:first_h2_start]
            })
            
        for i, match in enumerate(h2_iter):
            start_index = match.start()
            end_index = h2_iter[i+1].start() if i < len(h2_iter) - 1 else len(content)
            
            is_last = (i == len(h2_iter) - 1)
            sections.append({
                'type': 'conclusion' if is_last else f'body{i+1}',
                'startIndex': start_index,
                'endIndex': end_index,
                'content': content[start_index:end_index]
            })
            
        return sections

    def count_keywords_per_section(self, sections: List[Dict], keywords: List[str]) -> List[Dict]:
        result = []
        for section in sections:
            counts = {}
            for kw in keywords:
                counts[kw] = count_keyword_coverage(section['content'], kw)
            result.append({'type': section['type'], 'counts': counts})
        return result

    def count_keywords(self, content: str, keywords: List[str]) -> Dict[str, int]:
        counts = {}
        for kw in keywords:
            counts[kw] = count_keyword_coverage(content, kw)
        return counts

    def validate_section_balance(
        self,
        section_counts: List[Dict],
        keywords: List[str],
        min_target: Optional[int] = None,
        max_target: Optional[int] = None,
        auto_keywords: Optional[List[str]] = None,
    ) -> Dict:
        issues = []
        auto_keyword_set = set(auto_keywords or [])

        for kw in keywords:
            total_kw_count = sum(sc['counts'].get(kw, 0) for sc in section_counts)

            if kw in auto_keyword_set:
                if total_kw_count < 1:
                    issues.append(f"ì „ì²´ \"{kw}\" 0íšŒ (ìë™ í‚¤ì›Œë“œ ìµœì†Œ 1íšŒ í•„ìš”)")
                continue

            if min_target is not None and total_kw_count < min_target:
                deficit = min_target - total_kw_count
                issues.append(f"ì „ì²´ \"{kw}\" {total_kw_count}íšŒ (ìµœì†Œ {min_target}íšŒ í•„ìš”, {deficit}íšŒ ì¶”ê°€ í•„ìš”)")

            if max_target is not None and total_kw_count > max_target:
                excess = total_kw_count - max_target
                issues.append(f"ì „ì²´ \"{kw}\" {total_kw_count}íšŒ (ìµœëŒ€ {max_target}íšŒ í—ˆìš©, {excess}íšŒ ì‚­ì œ í•„ìš”)")

        if not issues:
            return {'passed': True}

        return {
            'passed': False,
            'reason': f"í‚¤ì›Œë“œ ì‚½ì… ë¯¸ë‹¬: {len(issues)}ê°œ ë¬¸ì œ",
            'feedback': ", ".join(issues)
        }

    def build_prompt(self, params: Dict[str, Any]) -> str:
        sections = params['sections']
        user_keywords = params['userKeywords']
        section_counts = params['sectionCounts']
        feedback = params.get('feedback', '')
        context_analysis = params.get('contextAnalysis') or {}
        min_target = params.get('minTarget', len(sections))
        max_target = params.get('maxTarget', min_target + 1)

        # Section Status
        section_status_lines = []
        for i, sc in enumerate(section_counts):
            kw_info = ", ".join([f"{kw}: {sc['counts'].get(kw, 0)}íšŒ" for kw in user_keywords])
            section_status_lines.append(f"[ì„¹ì…˜ {i}] {sc['type']}: {kw_info}")
        section_status = "\n".join(section_status_lines)

        # Per-keyword totals
        kw_totals = {}
        for kw in user_keywords:
            kw_totals[kw] = sum(sc['counts'].get(kw, 0) for sc in section_counts)

        # Problems
        problems = []
        for kw in user_keywords:
            total = kw_totals[kw]
            if total < min_target:
                deficit = min_target - total
                problems.append(f"ì „ì²´ \"{kw}\": {total}íšŒ â†’ {deficit}íšŒ ì¶”ê°€ ì‚½ì… í•„ìš” (ëª©í‘œ {min_target}íšŒ)")
            elif total > max_target:
                excess = total - max_target
                problems.append(f"ì „ì²´ \"{kw}\": {total}íšŒ â†’ {excess}íšŒ ì‚­ì œ í•„ìš” (ìµœëŒ€ {max_target}íšŒ)")
        
        tone_instruction = ""
        responsibility_target = context_analysis.get('responsibilityTarget')
        expected_tone = context_analysis.get('expectedTone')
        
        if responsibility_target and expected_tone:
            critical_keywords = [kw for kw in user_keywords if responsibility_target in kw or kw in responsibility_target]
            if critical_keywords:
                tone_instruction = f"""
## âš ï¸ í†¤ ì§€ì‹œ (í•„ìˆ˜)
ì´ ì›ê³ ì˜ ë…¼ì¡°: "{expected_tone}"
ë¹„íŒ/ìš”êµ¬ ëŒ€ìƒ: "{responsibility_target}"
â†’ "{', '.join(critical_keywords)}" í‚¤ì›Œë“œëŠ” **{expected_tone}ì  ë§¥ë½**ìœ¼ë¡œ ì‘ì„±í•  ê²ƒ
â†’ ì ˆëŒ€ ìš°í˜¸ì /ì¡´ê²½í•˜ëŠ” í‘œí˜„ ê¸ˆì§€ (ì˜ˆ: "ì¡´ê²½", "ê°ì‚¬", "ì„±ê³¼", "ë…¸ë ¥" ë“±)"""

        # [CRITICAL UPDATE] Full Context Preview
        # Join all sections to provide full context
        context_preview = ""
        if sections and len(sections) > 0:
            preview_text = " ".join([s['content'] for s in sections])
            # Strip tags for readability but keep structure roughly? 
            # Actually LLM reads HTML fine. Let's keep it simple or strip.
            # Stripping tags is better for token efficiency, assuming textual flow.
            preview_text = re.sub(r'<[^>]*>', '', preview_text)
            preview_text = re.sub(r'\s+', ' ', preview_text).strip()
            
            # Use a much larger limit or no limit (Gemini Flash has huge context)
            # 10,000 chars should cover any normal generated post.
            context_preview = f"""
## ì „ì²´ ì›ê³  ë‚´ìš© (ë°˜ë“œì‹œ ì½ê³  ë§¥ë½ì— ë§ê²Œ ì‘ì„±í•  ê²ƒ)
{preview_text[:12000]}
"""

        prompt = f"""ê²€ìƒ‰ì–´ê°€ ì „ì²´ {min_target}~{max_target}íšŒ ë²”ìœ„ì— ë“¤ì–´ì˜¤ë„ë¡ ìƒˆ ë¬¸ì¥ì„ ìƒì„±í•˜ê±°ë‚˜ ê¸°ì¡´ ë¬¸ì¥ì„ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤.
{context_preview}

## ê²€ìƒ‰ì–´
{chr(10).join([f'- "{kw}" (í˜„ì¬ {kw_totals.get(kw, 0)}íšŒ, ëª©í‘œ {min_target}íšŒ ì´ìƒ)' for kw in user_keywords])}

## í˜„ì¬ ì„¹ì…˜ë³„ í˜„í™©
{section_status}

## í•„ìš”í•œ ì¡°ì •
{chr(10).join(problems) if problems else 'ì¡°ì • ë¶ˆí•„ìš”'}
{tone_instruction}

## ê·œì¹™
1. âš ï¸ **[CRITICAL] ë§¥ë½ ì¼ì¹˜**: ìœ„ 'ì „ì²´ ì›ê³  ë‚´ìš©'ì„ ì½ê³ , í•´ë‹¹ ì„¹ì…˜ì˜ ë‚´ìš©ê³¼ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì§€ëŠ” ë¬¸ì¥ì„ ì‘ì„±í•˜ì‹­ì‹œì˜¤. 'ëœ¬ê¸ˆì—†ëŠ” ë¬¸ì¥'ì„ ì ˆëŒ€ ê¸ˆì§€í•©ë‹ˆë‹¤.
2. **ì „ì²´ í•©ê³„ ìš°ì„ **: í‚¤ì›Œë“œë³„ ì´í•©ì„ ë°˜ë“œì‹œ {min_target}~{max_target}íšŒë¡œ ë§ì¶”ì‹­ì‹œì˜¤.
3. **ë¶€ì¡± ì‹œ ë°°ì¹˜**: í˜„ì¬ 0íšŒì¸ ì„¹ì…˜ ë˜ëŠ” ë§¥ë½ì´ ë§ëŠ” ê¸´ ì„¹ì…˜ë¶€í„° ìš°ì„  ì‚½ì…í•˜ì‹­ì‹œì˜¤.
4. **ê²€ìƒ‰ì–´ ì›ë¬¸ ìœ ì§€**: "{user_keywords[0] if user_keywords else ''}" í˜•íƒœ ê·¸ëŒ€ë¡œ ì‚¬ìš©
5. **ì§§ì€ í•œ ë¬¸ì¥ë§Œ ìƒì„±**: 30ì~50ì ë‚´ì™¸ì˜ **ìì—°ìŠ¤ëŸ¬ìš´ í•œ ë¬¸ì¥**ë§Œ ìƒì„± (ë¬¸ë‹¨ ì „ì²´ ìƒì„± ê¸ˆì§€)
6. **ì‚¬ì‹¤ ê´€ê³„ ì£¼ì˜**: ì›ê³ ì— ì—†ëŠ” ë‚´ìš©ì„ ë‚ ì¡°í•˜ì§€ ë§ˆì‹­ì‹œì˜¤. (ì˜ˆ: ëŒ€í†µë ¹ í˜¸ì¹­, ê°€ì§œ ê³µì•½ ë“± ê¸ˆì§€)
7. **ìœ„ì¹˜ ì§€ì •**: ì„¹ì…˜ ë²ˆí˜¸ì™€ ë™ì‘(insert/delete) ëª…ì‹œ

## ì¶œë ¥ í˜•ì‹ (JSON)
{{"instructions":[{{"section":0,"action":"insert","sentence":"ë§¥ë½ì— ë§ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥"}}]}}

âš ï¸ ì¡°ì •ì´ í•„ìš” ì—†ìœ¼ë©´: {{"instructions":[]}}
âš ï¸ sentenceëŠ” 50ì ì´ë‚´, ì¤„ë°”ê¿ˆ ê¸ˆì§€"""

        if feedback:
            prompt += f"\n\nğŸš¨ ì´ì „ ì‹œë„ ì‹¤íŒ¨: {feedback}"
        
        return prompt

    def parse_instructions(self, response: str) -> List[Dict]:
        if not response:
            return []
        
        try:
            text = re.sub(r'```(?:json)?\s*([\s\S]*?)```', r'\1', response).strip()
            text = re.sub(r'[\r\n]+', ' ', text)
            
            json_match = re.search(r'\{[\s\S]*\}', text)
            if json_match:
                text = json_match.group(0)
            
            parsed = json.loads(text)
            instructions = parsed.get('instructions', [])
            
            validated = []
            for ins in instructions:
                if ins.get('action') != 'insert' or not ins.get('sentence'):
                    validated.append(ins)
                    continue

                sentence = ins['sentence'].strip()
                if len(sentence) > 300: # Increased limit slightly as we allow slightly longer context
                    print(f"âš ï¸ [KeywordInjectorAgent] ë¬¸ì¥ ë„ˆë¬´ ê¹€ ({len(sentence)}ì)")
                    # but maybe allow it if context insists? No, keep it checks.
                    # Strict limit 200 is safer to prevent rambling.
                    if len(sentence) > 200:
                         print("   -> 200ì ì´ˆê³¼ë¡œ ê±°ë¶€")
                         continue
                
                # Filter '...' pattern
                if '...' in sentence and sentence.find('...') < len(sentence) - 5:
                     continue
                
                # Filter greeting duplication
                if 'ì¡´ê²½í•˜ëŠ”' in sentence and 'ì•ˆë…•í•˜ì‹­ë‹ˆê¹Œ' in sentence:
                     print(f"âš ï¸ [KeywordInjectorAgent] ì¸ì‚¬ë§ ë³µì‚¬ ê°ì§€ - ê±°ë¶€")
                     continue

                validated.append(ins)
            
            return validated
            
        except Exception as e:
            print(f"âš ï¸ [KeywordInjectorAgent] JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
            return []

    def apply_instructions(self, content: str, sections: List[Dict], instructions: List[Dict]) -> str:
        if not instructions:
            return content
        
        sorted_ins = sorted(instructions, key=lambda x: x.get('section', -1), reverse=True)
        result = content
        
        for ins in sorted_ins:
            section_idx = ins.get('section')
            if section_idx is None or section_idx < 0 or section_idx >= len(sections):
                continue
            
            section = sections[section_idx]
            
            if ins.get('action') == 'insert' and ins.get('sentence'):
                # Insert at end of section?
                # Best place is typically end of section paragraph.
                insert_pos = section['endIndex']
                # Add newline <p>sentence</p>
                new_paragraph = f"\n<p>{ins['sentence']}</p>"
                result = result[:insert_pos] + new_paragraph + result[insert_pos:]
                print(f"ğŸ“ [KeywordInjectorAgent] ì„¹ì…˜ {section_idx}ì— ì‚½ì…: \"{ins['sentence'][:50]}...\"")
            
            elif ins.get('action') == 'delete':
                print(f"ğŸ—‘ï¸ [KeywordInjectorAgent] ì„¹ì…˜ {section_idx}ì—ì„œ ì‚­ì œ ì‹œë„ (ìŠ¤í‚µë¨)")
        
        return result
