
import re
import json
import logging
import time
from typing import Dict, Any, Optional, List

# API Call Timeout (seconds)
LLM_CALL_TIMEOUT = 120  # 2ë¶„ íƒ€ì„ì•„ì›ƒ
CONTEXT_ANALYZER_TIMEOUT = 60  # 1ë¶„ íƒ€ì„ì•„ì›ƒ

# Local imports
from ..common.classifier import classify_topic
from ..common.warnings import generate_non_lawmaker_warning, generate_family_status_warning
from ..common.theminjoo import get_party_stance
from ..common.election_rules import get_election_stage, get_prompt_instruction
from ..common.seo import build_seo_instruction
from ..common.constants import resolve_writing_method

# Template Builders
from ..templates.daily_communication import build_daily_communication_prompt
from ..templates.activity_report import build_activity_report_prompt
from ..templates.policy_proposal import build_policy_proposal_prompt
from ..templates.current_affairs import build_critical_writing_prompt, build_diagnosis_writing_prompt
from ..templates.local_issues import build_local_issues_prompt

# Template Builders Mapping
TEMPLATE_BUILDERS = {
    'emotional_writing': build_daily_communication_prompt,
    'logical_writing': build_policy_proposal_prompt, # Mapped buildLogicalWritingPrompt to policy proposal
    'direct_writing': build_activity_report_prompt,
    'critical_writing': build_critical_writing_prompt,
    'diagnostic_writing': build_diagnosis_writing_prompt,
    'analytical_writing': build_local_issues_prompt
}

logger = logging.getLogger(__name__)

def strip_html(text: str) -> str:
    if not text:
        return ''
    text = re.sub(r'<[^>]*>', '', text)
    return re.sub(r'\s+', '', text).strip()

def normalize_artifacts(text: str) -> str:
    if not text:
        return ''
    cleaned = text.strip()
    cleaned = re.sub(r'```[\s\S]*?```', '', cleaned).strip()
    cleaned = re.sub(r'^\s*\\"', '', cleaned)
    cleaned = re.sub(r'\\"?\s*$', '', cleaned)
    cleaned = re.sub(r'^\s*["â€œ]', '', cleaned)
    cleaned = re.sub(r'["â€]\s*$', '', cleaned)
    
    # Remove metadata lines if any (Robust Regex)
    # Catch 'ì¹´í…Œê³ ë¦¬:', 'ê²€ìƒ‰ì–´...', 'ìƒì„± ì‹œê°„:' and everything after them until end of string
    # We use [\s\S]* to match all characters including newlines
    cleaned = re.sub(r'(\**ì¹´í…Œê³ ë¦¬\**|\**ê²€ìƒ‰ì–´ ì‚½ì… íšŸìˆ˜\**|\**ìƒì„± ì‹œê°„\**):[\s\S]*$', '', cleaned).strip()
    
    cleaned = re.sub(r'"content"\s*:\s*', '', cleaned)
    
    return cleaned.strip()

from ..base_agent import Agent

class StructureAgent(Agent):
    def __init__(self, name: str = 'StructureAgent', options: Optional[Dict[str, Any]] = None):
        super().__init__(name, options)

        # ê³µí†µ Gemini í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš© (ìƒˆ google-genai SDK)
        from ..common.gemini_client import get_client, DEFAULT_MODEL
        self.model_name = DEFAULT_MODEL

        # í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” í™•ì¸
        client = get_client()
        if client:
            print(f"ğŸ¤– [StructureAgent] ëª¨ë¸: {self.model_name}")
        else:
            print(f"âš ï¸ [StructureAgent] Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨")

    async def process(self, context: Dict[str, Any]) -> Dict[str, Any]:
        topic = context.get('topic', '')
        user_profile = context.get('userProfile', {})
        # ë°©ì–´ ì½”ë“œ - listë¡œ ì „ë‹¬ë˜ëŠ” ê²½ìš° ë°©ì–´
        if not isinstance(user_profile, dict):
            user_profile = {}
        category = context.get('category', '')
        sub_category = context.get('subCategory', '')
        instructions = context.get('instructions', '')
        news_context = context.get('newsContext', '')
        # ğŸ”‘ [NEW] ì…ì¥ë¬¸ê³¼ ë‰´ìŠ¤/ë°ì´í„° ë¶„ë¦¬
        stance_text = context.get('stanceText', '')
        news_data_text = context.get('newsDataText', '')
        target_word_count = context.get('targetWordCount', 2000)
        user_keywords = context.get('userKeywords', [])
        memory_context = context.get('memoryContext', '')

        print(f"ğŸš€ [StructureAgent] ì‹œì‘ - ì¹´í…Œê³ ë¦¬: {category or '(ìë™)'}, ì£¼ì œ: {topic}")
        print(f"ğŸ“Š [StructureAgent] ì…ì¥ë¬¸: {len(stance_text)}ì, ë‰´ìŠ¤/ë°ì´í„°: {len(news_data_text)}ì")

        # 1. Determine Writing Method
        writing_method = ''
        if category and category != 'auto':
            writing_method = resolve_writing_method(category, sub_category)
            print(f"âœï¸ [StructureAgent] ì‘ë²• ì„ íƒ (ì¹´í…Œê³ ë¦¬ ê¸°ë°˜): {writing_method}")
        else:
            classification = await classify_topic(topic)
            writing_method = classification['writingMethod']
            print(f"ğŸ¤– [StructureAgent] ì‘ë²• ìë™ ì¶”ë¡ : {writing_method} (ì‹ ë¢°ë„: {classification.get('confidence')}, ì†ŒìŠ¤: {classification.get('source')})")

        # 2. Build Author Bio
        author_bio, author_name = self.build_author_bio(user_profile)

        # 3. Get Party Stance
        party_stance_guide = None
        try:
             party_stance_guide = get_party_stance(topic)
        except Exception as e:
             print(f"âš ï¸ [StructureAgent] ë‹¹ë¡  ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

        # 4. ContextAnalyzer (ì…ì¥ë¬¸/ë‰´ìŠ¤ ë¶„ë¦¬ ì²˜ë¦¬)
        context_analysis = await self.run_context_analyzer(
            stance_text or instructions,  # ì…ì¥ë¬¸ ìš°ì„ , ì—†ìœ¼ë©´ ê¸°ì¡´ instructions ì‚¬ìš©
            news_data_text or news_context,  # ë‰´ìŠ¤ ë°ì´í„° ìš°ì„ , ì—†ìœ¼ë©´ ê¸°ì¡´ newsContext ì‚¬ìš©
            author_name
        )

        # 5. Build Prompt
        prompt = self.build_prompt({
            'topic': topic,
            'category': category,
            'writingMethod': writing_method,
            'authorName': author_name,
            'authorBio': author_bio,
            'instructions': instructions,
            'newsContext': news_context,
            'targetWordCount': target_word_count,
            'partyStanceGuide': party_stance_guide,
            'contextAnalysis': context_analysis,
            'userProfile': user_profile,
            'memoryContext': memory_context,
            'userKeywords': user_keywords
        })

        print(f"ğŸ“ [StructureAgent] í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ ({len(prompt)}ì)")

        # 6. Retry Loop (ê²€ì¦ ë¡œì§ ì—„ê²©í•˜ê²Œ ë³µêµ¬, ëŒ€ì‹  í”„ë¡¬í”„íŠ¸ë¥¼ ê°•í™”í•˜ì—¬ ì„±ê³µë¥  ì œê³ )
        max_retries = 2
        attempt = 0
        feedback = ''
        validation = {}
        last_error = None  # ë§ˆì§€ë§‰ ì˜ˆì™¸ ì¶”ì 

        while attempt <= max_retries:
            attempt += 1
            print(f"ğŸ”„ [StructureAgent] ìƒì„± ì‹œë„ {attempt}/{max_retries + 1}")

            current_prompt = prompt
            if feedback:
                current_prompt += f"\n\nğŸš¨ [ì¤‘ìš” - ì¬ì‘ì„± ì§€ì‹œ] ì´ì „ ì‘ì„±ë³¸ì´ ë‹¤ìŒ ì´ìœ ë¡œ ë°˜ë ¤ë˜ì—ˆìŠµë‹ˆë‹¤:\n\"{feedback}\"\n\níŠ¹íˆ **ë¶„ëŸ‰ ë¶€ì¡±**ì´ ë¬¸ì œë¼ë©´, ê° ë³¸ë¡  ì„¹ì…˜ì˜ **ì‚¬ë¡€ì™€ ê·¼ê±°**ë¥¼ ëŒ€í­ ë³´ê°•í•˜ì—¬ ë¬´ì¡°ê±´ **ì§€ì •ëœ ë¶„ëŸ‰(2000ì ì´ìƒ)**ì„ ë„˜ê¸°ì‹­ì‹œì˜¤. ìš”ì•½í•˜ì§€ ë§ê³  ìƒì„¸íˆ ì„œìˆ í•˜ì‹­ì‹œì˜¤."

            try:
                response = await self.call_llm(current_prompt)
                print(f"ğŸ“¥ [StructureAgent] LLM ì›ë³¸ ì‘ë‹µ ({len(response)}ì)")

                structured = self.parse_response(response)
                content = normalize_artifacts(structured['content'])
                title = normalize_artifacts(structured['title'])

                content = normalize_artifacts(structured['content'])
                title = normalize_artifacts(structured['title'])

                validation = self.validate_output(content, target_word_count)

                if validation['passed']:
                    print(f"âœ… [StructureAgent] ê²€ì¦ í†µê³¼: {len(strip_html(content))}ì")

                    if not title.strip():
                        title = topic[:20] if topic else 'ìƒˆ ì›ê³ '

                    return {
                        'content': content,
                        'title': title,
                        'writingMethod': writing_method,
                        'contextAnalysis': context_analysis
                    }

                print(f"âš ï¸ [StructureAgent] ê²€ì¦ ì‹¤íŒ¨: {validation['reason']}")
                feedback = validation['feedback']
                last_error = None  # ê²€ì¦ ì‹¤íŒ¨ëŠ” ì˜ˆì™¸ê°€ ì•„ë‹˜

            except Exception as e:
                error_msg = str(e)
                print(f"âŒ [StructureAgent] ì—ëŸ¬ ë°œìƒ: {error_msg}")
                feedback = error_msg
                last_error = error_msg  # ì˜ˆì™¸ ë©”ì‹œì§€ ì €ì¥

            if attempt > max_retries:
                # ë§ˆì§€ë§‰ ì—ëŸ¬ê°€ ì˜ˆì™¸ë©´ ê·¸ ë©”ì‹œì§€ ì‚¬ìš©, ì•„ë‹ˆë©´ ê²€ì¦ ì‹¤íŒ¨ ì´ìœ  ì‚¬ìš©
                final_reason = last_error or validation.get('reason', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')
                raise Exception(f"StructureAgent ì‹¤íŒ¨ ({max_retries}íšŒ ì¬ì‹œë„ í›„): {final_reason}")

    async def call_llm(self, prompt: str) -> str:
        from ..common.gemini_client import generate_content_async

        print(f"ğŸ“¤ [StructureAgent] LLM í˜¸ì¶œ ì‹œì‘")
        start_time = time.time()

        try:
            response_text = await generate_content_async(
                prompt,
                model_name=self.model_name,
                temperature=0.25,  # Node.js parity: 0.25 for strict instruction adherence
                max_output_tokens=8192
            )

            elapsed = time.time() - start_time
            print(f"âœ… [StructureAgent] LLM ì‘ë‹µ ì™„ë£Œ ({elapsed:.1f}ì´ˆ)")

            return response_text

        except Exception as e:
            elapsed = time.time() - start_time
            error_msg = str(e)
            print(f"âŒ [StructureAgent] LLM í˜¸ì¶œ ì‹¤íŒ¨ ({elapsed:.1f}ì´ˆ): {error_msg}")

            # íƒ€ì„ì•„ì›ƒ ê´€ë ¨ ì—ëŸ¬ ë©”ì‹œì§€ ê°œì„ 
            if 'timeout' in error_msg.lower() or 'deadline' in error_msg.lower():
                raise Exception(f"LLM í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ ({elapsed:.1f}ì´ˆ). Gemini APIê°€ ì‘ë‹µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            raise

    async def run_context_analyzer(self, stance_text: str, news_data_text: str, author_name: str) -> Optional[Dict]:
        from ..common.gemini_client import generate_content_async

        # ì…ì¥ë¬¸ì´ ì—†ìœ¼ë©´ ë¶„ì„ ìŠ¤í‚µ
        if len(stance_text) < 50:
            print(f"âš ï¸ [StructureAgent] ì…ì¥ë¬¸ì´ ë„ˆë¬´ ì§§ìŒ ({len(stance_text)}ì) - ContextAnalyzer ìŠ¤í‚µ")
            return None

        print(f'ğŸ” [StructureAgent] ContextAnalyzer ì‹¤í–‰... (ì…ì¥ë¬¸: {len(stance_text)}ì, ë‰´ìŠ¤: {len(news_data_text)}ì)')
        start_time = time.time()

        if not news_data_text:
            # Fallback Logic: ë‰´ìŠ¤ ë°ì´í„° ì—†ì„ ë•Œ - ê·¸ëƒ¥ ì§„í–‰
            # (user_profileì´ ì´ í•¨ìˆ˜ scopeì— ì—†ì–´ì„œ fallback ë¡œì§ ë¹„í™œì„±í™”)
            print(f"âš ï¸ [StructureAgent] ë‰´ìŠ¤ ë°ì´í„° ì—†ìŒ - ì…ì¥ë¬¸ë§Œìœ¼ë¡œ ë¶„ì„ ì§„í–‰")

        context_prompt = f"""ë‹¹ì‹ ì€ ì •ì¹˜ ì½˜í…ì¸  ì „ëµê°€ì…ë‹ˆë‹¤. ì•„ë˜ ì…ì¥ë¬¸ì„ ë¶„ì„í•˜ì—¬ ë¸”ë¡œê·¸ ì½˜í…ì¸  ì „ëµì„ ìˆ˜ë¦½í•˜ì„¸ìš”.

[ì…ì¥ë¬¸ ì›ë¬¸]
{stance_text[:2500]}

[ë‰´ìŠ¤/ë°ì´í„° (ìˆìœ¼ë©´)]
{news_data_text[:2000] if news_data_text else '(ì—†ìŒ)'}

## ë¶„ì„ ê³¼ì œ

### 1. ê¸€ì˜ í•µì‹¬ ì˜ë„ (Intent)
ì•„ë˜ ì¤‘ ê°€ì¥ ì í•©í•œ ê²ƒ í•˜ë‚˜ë¥¼ ì„ íƒ:
- "donation_request": í›„ì› ìš”ì²­ (ê³„ì¢Œ, ì—°ë½ì²˜ í¬í•¨)
- "policy_promotion": ì •ì±…/ë¹„ì „ í™ë³´
- "event_announcement": ì¼ì •/í–‰ì‚¬ ì•ˆë‚´
- "activity_report": í™œë™ ë³´ê³ 
- "personal_message": ê°œì¸ ì†Œí†µ/ì¸ì‚¬

### 2. ì½˜í…ì¸  ì „ëµ (ContentStrategy)
ì´ ê¸€ì„ 2000ì ë¸”ë¡œê·¸ë¡œ í™•ì¥í•  ë•Œ:
- tone: ì–´ë–¤ í†¤ì•¤ë§¤ë„ˆ? ("ê°ì„± í˜¸ì†Œ", "ë…¼ë¦¬ì  ì„¤ë“", "ì •ë³´ ì „ë‹¬", "ì¹œê·¼í•œ ì†Œí†µ")
- structure: ì–´ë–¤ êµ¬ì¡°? ("ìŠ¤í† ë¦¬í…”ë§ â†’ ë¹„ì „ â†’ CTA", "ë¬¸ì œ â†’ í•´ë²• â†’ íš¨ê³¼", "ì¼ì • â†’ ë‚´ìš© â†’ ì°¸ì—¬ë°©ë²•")
- emphasis: ë¬´ì—‡ì„ ê°•ì¡°? (ë¦¬ìŠ¤íŠ¸ë¡œ)

### 3. í•µì‹¬ ì£¼ì¥ ì¶”ì¶œ (MustIncludeFromStance)
ê¸€ì“´ì´({author_name})ì˜ í•µì‹¬ ì£¼ì¥ ìµœëŒ€ 3ê°œ, ê°ê°ì— ëŒ€í•´:
- topic: í•µì‹¬ ì£¼ì¥ (ê°„ê²°í•œ ë¬¸ì¥)
- expansion_why: ì´ ì£¼ì¥ì´ í•„ìš”í•œ ë°°ê²½
- expansion_how: êµ¬ì²´ì  ì‹¤í˜„ ë°©ì•ˆ
- expansion_effect: ê¸°ëŒ€ë˜ëŠ” íš¨ê³¼

### 4. í•„ìˆ˜ ë³´ì¡´ ì •ë³´ (MustPreserve) âš ï¸ ì¤‘ìš”
ì›ë¬¸ì—ì„œ **ì ˆëŒ€ ëˆ„ë½ë˜ë©´ ì•ˆ ë˜ëŠ” êµ¬ì²´ì  ì •ë³´**ë¥¼ ì¶”ì¶œ:
- bankName: ì€í–‰ëª… (ì—†ìœ¼ë©´ null)
- accountNumber: ê³„ì¢Œë²ˆí˜¸ (ì—†ìœ¼ë©´ null)
- accountHolder: ì˜ˆê¸ˆì£¼ (ì—†ìœ¼ë©´ null)
- contactNumber: ì—°ë½ì²˜ (ì—†ìœ¼ë©´ null)
- instruction: ì•ˆë‚´ ë¬¸êµ¬ (ì—†ìœ¼ë©´ null)
- eventDate: ì¼ì‹œ (ì—†ìœ¼ë©´ null)
- eventLocation: ì¥ì†Œ (ì—†ìœ¼ë©´ null)
- ctaPhrase: CTA ë¬¸êµ¬, ì˜ˆ: "í•¨ê»˜í•´ ì£¼ì‹­ì‹œì˜¤" (ì—†ìœ¼ë©´ null)

ë°˜ë“œì‹œ ì•„ë˜ JSON í¬ë§·ìœ¼ë¡œ ì‘ë‹µ:
{{
  "intent": "donation_request",
  "contentStrategy": {{
    "tone": "ê°ì„± í˜¸ì†Œ",
    "structure": "ìŠ¤í† ë¦¬í…”ë§ â†’ ë¹„ì „ â†’ CTA",
    "emphasis": ["í›„ì› ë™ì°¸ ìœ ë„", "ì§„ì •ì„± ì „ë‹¬"]
  }},
  "mustIncludeFromStance": [
    {{
      "topic": "í•µì‹¬ ì£¼ì¥ 1",
      "expansion_why": "ë°°ê²½...",
      "expansion_how": "ë°©ì•ˆ...",
      "expansion_effect": "íš¨ê³¼..."
    }}
  ],
  "mustIncludeFacts": [],
  "mustPreserve": {{
    "bankName": "ì‹ í•œì€í–‰",
    "accountNumber": "140016005619",
    "accountHolder": "ì´ì¬ì„± í›„ì›íšŒ",
    "contactNumber": "01097262663",
    "instruction": "ì…ê¸ˆ í›„ ì„±í•¨ ë¬¸ì â†’ ì˜ìˆ˜ì¦ ë°œê¸‰",
    "eventDate": null,
    "eventLocation": null,
    "ctaPhrase": "ì§€ê¸ˆ ë°”ë¡œ í•¨ê»˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
  }}
}}"""

        try:
            response_text = await generate_content_async(
                context_prompt,
                model_name=self.model_name,
                temperature=0.0,  # ë¶„ì„ì€ ì •í™•ë„ ìš°ì„ 
                response_mime_type='application/json'
            )

            analysis = json.loads(response_text)

            elapsed = time.time() - start_time
            print(f"âœ… [StructureAgent] ContextAnalyzer ì™„ë£Œ ({elapsed:.1f}ì´ˆ)")

            # Filter phrases
            if 'mustIncludeFromStance' in analysis and isinstance(analysis['mustIncludeFromStance'], list):
                filtered_list = []
                for item in analysis['mustIncludeFromStance']:
                    # ê¸°ì¡´ ë¬¸ìì—´ í˜¸í™˜ì„± (stringì´ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©)
                    if isinstance(item, str) and len(item.strip()) >= 5:
                         filtered_list.append({'topic': item, 'expansion_why': '', 'expansion_how': '', 'expansion_effect': ''})
                    # ë”•ì…”ë„ˆë¦¬ êµ¬ì¡° í•„í„°ë§
                    elif isinstance(item, dict) and item.get('topic'):
                        topic = item.get('topic', '').strip()
                        if len(topic) >= 2 and not topic.startswith('âš ï¸'):
                            filtered_list.append(item)
                analysis['mustIncludeFromStance'] = filtered_list

            return analysis
        except Exception as e:
            elapsed = time.time() - start_time
            error_msg = str(e)
            print(f"âš ï¸ [StructureAgent] ContextAnalyzer ì‹¤íŒ¨ ({elapsed:.1f}ì´ˆ): {error_msg} - ê±´ë„ˆëœ€")
            return None

    def build_prompt(self, params: Dict[str, Any]) -> str:
        # Extract params
        writing_method = params.get('writingMethod')
        template_builder = TEMPLATE_BUILDERS.get(writing_method, build_daily_communication_prompt)

        # userProfile ë°©ì–´ ì½”ë“œ - listë¡œ ì „ë‹¬ë˜ëŠ” ê²½ìš° ë°©ì–´
        user_profile = params.get('userProfile', {})
        if not isinstance(user_profile, dict):
            user_profile = {}

        # Build base template prompt
        template_prompt = template_builder({
            'topic': params.get('topic'),
            'authorBio': params.get('authorBio'),
            'authorName': params.get('authorName'),
            'instructions': params.get('instructions'),
            'keywords': params.get('userKeywords'),
            'targetWordCount': params.get('targetWordCount'),
            'personalizedHints': params.get('memoryContext'),
            'newsContext': params.get('newsContext'),
            'isCurrentLawmaker': self.is_current_lawmaker(user_profile),
            'politicalExperience': user_profile.get('politicalExperience', 'ì •ì¹˜ ì‹ ì¸'),
            'familyStatus': user_profile.get('familyStatus', '')
        })

        # Reference Materials Section
        source_text = "\n\n---\n\n".join(filter(None, [params.get('instructions'), params.get('newsContext')]))
        ref_section = ""
        if source_text.strip():
            ref_section = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ“š [1ì°¨ ìë£Œ] ì°¸ê³ ìë£Œ - ì›ê³ ì˜ í•µì‹¬ ì†ŒìŠ¤                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âš ï¸ **[CRITICAL] ì•„ë˜ ì°¸ê³ ìë£Œê°€ ì´ ì›ê³ ì˜ 1ì°¨ ìë£Œ(Primary Source)ì…ë‹ˆë‹¤.**
- ì²« ë²ˆì§¸ ìë£Œ: ì‘ì„±ìì˜ ì…ì¥ë¬¸/í˜ì´ìŠ¤ë¶ ê¸€ (í•µì‹¬ ë…¼ì¡°ì™€ ì£¼ì¥)
- ì´í›„ ìë£Œ: ë‰´ìŠ¤/ë°ì´í„° (ê·¼ê±°, íŒ©íŠ¸, ë°°ê²½ ì •ë³´)

**[ì°¸ê³ ìë£Œ ì›ë¬¸]**
{source_text[:6000]}

ğŸš¨ **[ìë£Œ ì²˜ë¦¬ ê·œì¹™ - ì¤‘ìš”]**
1. **ì •ë³´ ì¶”ì¶œ**: ì°¸ê³ ìë£Œì—ì„œ í•µì‹¬ íŒ©íŠ¸, ìˆ˜ì¹˜, ë…¼ì ë§Œ ì¶”ì¶œí•˜ì„¸ìš”.
2. **ì¬ì‘ì„± í•„ìˆ˜ (CRITICAL)**: ì¶”ì¶œí•œ ì •ë³´ë¥¼ **ë°˜ë“œì‹œ ìƒˆë¡œìš´ ë¬¸ì¥ìœ¼ë¡œ ë‹¤ì‹œ ì‘ì„±**í•˜ì„¸ìš”. ì°¸ê³ ìë£Œì˜ ë¬¸ì¥ì„ ê·¸ëŒ€ë¡œ ë³µì‚¬í•˜ì§€ ë§ˆì„¸ìš”.
3. **êµ¬ì–´ì²´ â†’ ë¬¸ì–´ì²´ ë³€í™˜**: ì¸í„°ë·°/ëŒ€í™”ì²´ ìë£Œì˜ ê²½ìš°, êµ¬ì–´ì²´ í‘œí˜„("ê·¸ë˜ì„œìš”", "ê±°ì˜ˆìš”", "~í•˜ê±°ë“ ìš”" ë“±)ì„ ë¬¸ì–´ì²´ë¡œ ë³€í™˜í•˜ì„¸ìš”.
4. **ì°½ì‘ ê¸ˆì§€**: ì°¸ê³ ìë£Œì— ì—†ëŠ” íŒ©íŠ¸, ìˆ˜ì¹˜ë¥¼ ì°½ì‘í•˜ì§€ ë§ˆì„¸ìš”.
5. **ì£¼ì œ ìœ ì§€**: ì°¸ê³ ìë£Œì˜ ì£¼ì œë¥¼ ë²—ì–´ë‚˜ì§€ ë§ˆì„¸ìš”.
6. **ë³´ì¡° ìë£Œ**: ì‚¬ìš©ì í”„ë¡œí•„(Bio)ì€ í™”ì ì •ì²´ì„±ê³¼ ì–´ì¡° ì°¸ê³ ìš©ì´ë©°, ë¶„ëŸ‰ì´ ë¶€ì¡±í•  ë•Œë§Œ í™œìš©í•˜ì„¸ìš”.

âŒ **ê¸ˆì§€ ì˜ˆì‹œ**:
- ì°¸ê³ ìë£Œ: "ì •í™•í•˜ê²Œ ì–˜ê¸°ë¥¼ í•˜ë©´ ê·¸ë˜ì„œ ì°½ì˜ì ì´ê³  ì •ë§ ì••ë„ì ì¸..."
- âŒ ì˜ëª»ëœ ì‚¬ìš©: "ì •í™•í•˜ê²Œ ì–˜ê¸°ë¥¼ í•˜ë©´ ê·¸ë˜ì„œ ì°½ì˜ì ì´ê³ ..." (ë³µë¶™)
- âœ… ì˜¬ë°”ë¥¸ ì‚¬ìš©: "ì°½ì˜ì ì´ê³  ì••ë„ì ì¸ ì½˜í…ì¸  ê¸°ë°˜ ì „ëµì´ í•µì‹¬ì…ë‹ˆë‹¤." (ì¬ì‘ì„±)
"""
            print(f"ğŸ“š [StructureAgent] ì°¸ê³ ìë£Œ ì£¼ì… ì™„ë£Œ: {len(source_text)}ì")
        else:
            print("âš ï¸ [StructureAgent] ì°¸ê³ ìë£Œ ì—†ìŒ - ì‚¬ìš©ì í”„ë¡œí•„ë§Œìœ¼ë¡œ ìƒì„±")

        # Context Injection
        context_injection = ""
        context_analysis = params.get('contextAnalysis')
        if context_analysis:
            stance_list = context_analysis.get('mustIncludeFromStance', [])
            
            # êµ¬ì¡°í™”ëœ stance ì²˜ë¦¬
            formatted_stances = []
            for i, p in enumerate(stance_list):
                if isinstance(p, dict):
                    topic = p.get('topic', '')
                    why_txt = p.get('expansion_why', '')
                    how_txt = p.get('expansion_how', '')
                    eff_txt = p.get('expansion_effect', '')
                    
                    block = f"""
{i+1}. **{topic}** (ë³¸ë¡  {i+1} ì£¼ì œ)
   - [Why/ë°°ê²½]: {why_txt}
   - [How/í•´ë²•]: {how_txt}
   - [Effect/íš¨ê³¼]: {eff_txt}"""
                    formatted_stances.append(block.strip())
                else:
                    # Fallback for string (legacy)
                    formatted_stances.append(f"{i+1}. {p}")

            stance_phrases = "\n\n".join(formatted_stances)
            stance_count = len(stance_list)
            
            if stance_count > 0:
                context_injection = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ”´ [MANDATORY] ë³¸ë¡  ì„¹ì…˜ë³„ í™•ì¥ ì„¤ê³„ë„ (Deep Expansion)       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ì•„ë˜ **{stance_count}ê°œ ì„¤ê³„ë„**ì— ë”°ë¼ ê° ë³¸ë¡  ì„¹ì…˜ì„ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
ë‹¨ìˆœíˆ ì£¼ì œë§Œ ì–¸ê¸‰í•˜ì§€ ë§ê³ , í•¨ê»˜ ì œê³µëœ [Why-How-Effect] ë…¼ë¦¬ë¥¼ ë¬¸ë‹¨ êµ¬ì„±ì— ë°˜ë“œì‹œ ë°˜ì˜í•´ì•¼ í•©ë‹ˆë‹¤.

{stance_phrases}

ğŸ“Œ **ì‘ì„± ì§€ì¹¨**:
1. ìœ„ {stance_count}ê°œ ì£¼ì œë¥¼ ê°ê° **ë³„ë„ì˜ ë³¸ë¡  ì„¹ì…˜(H2)**ìœ¼ë¡œ êµ¬ì„±í•˜ì‹­ì‹œì˜¤.
2. ê° ì„¹ì…˜ ì‘ì„± ì‹œ, ìœ„ì—ì„œ ì„¤ê³„ëœ [Why], [How], [Effect] ë‚´ìš©ì„ ë¹ ì§ì—†ì´ ì„œìˆ í•˜ì—¬ ë¶„ëŸ‰ì„ í™•ë³´í•˜ê³  ë…¼ë¦¬ë¥¼ ì™„ì„±í•˜ì‹­ì‹œì˜¤.
3. **[How] ë‹¨ê³„**ì—ì„œ ë‹¹ì‹ ì˜ Bio(ê²½ë ¥)ë¥¼ ê·¼ê±°ë¡œ í™œìš©í•˜ì—¬ ì „ë¬¸ì„±ì„ ë“œëŸ¬ë‚´ì‹­ì‹œì˜¤.
"""

            # ğŸ”´ [NEW] contentStrategy ì£¼ì…
            content_strategy = context_analysis.get('contentStrategy', {})
            if content_strategy:
                tone = content_strategy.get('tone', '')
                structure = content_strategy.get('structure', '')
                emphasis = content_strategy.get('emphasis', [])
                
                if tone or structure:
                    emphasis_str = ", ".join(emphasis) if emphasis else "ì—†ìŒ"
                    context_injection += f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ¯ [STRATEGY] ì½˜í…ì¸  ì „ëµ ê°€ì´ë“œ                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

**[í†¤ì•¤ë§¤ë„ˆ]**: {tone}
**[êµ¬ì¡°]**: {structure}
**[ê°•ì¡°ì ]**: {emphasis_str}

ìœ„ ì „ëµì— ë§ì¶° ê¸€ì„ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
"""
                    print(f"ğŸ¯ [StructureAgent] ì½˜í…ì¸  ì „ëµ ì£¼ì…: {tone} / {structure}")

            # ğŸ”´ [NEW] mustPreserve ê¸°ë°˜ CTA ì •ë³´ ì£¼ì…
            must_preserve = context_analysis.get('mustPreserve', {})
            intent = context_analysis.get('intent', '')
            
            if must_preserve and intent == 'donation_request':
                bank_name = must_preserve.get('bankName')
                account_number = must_preserve.get('accountNumber')
                account_holder = must_preserve.get('accountHolder')
                contact_number = must_preserve.get('contactNumber')
                instruction = must_preserve.get('instruction')
                cta_phrase = must_preserve.get('ctaPhrase')
                
                # ìœ íš¨í•œ ì •ë³´ê°€ ìˆìœ¼ë©´ ì£¼ì…
                if account_number or contact_number:
                    cta_parts = []
                    if bank_name and account_number:
                        cta_parts.append(f"- í›„ì›ê³„ì¢Œ: {bank_name} {account_number}")
                    if account_holder:
                        cta_parts.append(f"- ì˜ˆê¸ˆì£¼: {account_holder}")
                    if contact_number and instruction:
                        cta_parts.append(f"- ì—°ë½ì²˜: {contact_number} ({instruction})")
                    elif contact_number:
                        cta_parts.append(f"- ì—°ë½ì²˜: {contact_number}")
                    if cta_phrase:
                        cta_parts.append(f"- CTA ë¬¸êµ¬: \"{cta_phrase}\"")
                    
                    cta_text = "\n".join(cta_parts)
                    
                    context_injection += f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ’° [CRITICAL] í›„ì› ì •ë³´ - ê²°ë¡ ë¶€ì— ë°˜ë“œì‹œ í¬í•¨               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ì´ ê¸€ì˜ í•µì‹¬ ëª©ì ì€ **í›„ì› ìš”ì²­**ì…ë‹ˆë‹¤. 
ê²°ë¡ ë¶€ì—ì„œ ì•„ë˜ í›„ì› ì •ë³´ë¥¼ **ìì—°ìŠ¤ëŸ½ê²Œ ì•ˆë‚´**í•˜ì‹­ì‹œì˜¤.

**[í›„ì› ì•ˆë‚´ ì •ë³´]**
{cta_text}

ğŸ“Œ **ì‘ì„± ì§€ì¹¨**:
1. ê²°ë¡ ë¶€ì—ì„œ í›„ì› ì°¸ì—¬ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ìš”ì²­í•˜ì‹­ì‹œì˜¤.
2. í›„ì› ê³„ì¢Œì™€ ì—°ë½ì²˜ ì •ë³´ë¥¼ ëª…ì‹œì ìœ¼ë¡œ í¬í•¨í•˜ì‹­ì‹œì˜¤.
3. CTA ë¬¸êµ¬("{cta_phrase or 'í•¨ê»˜í•´ ì£¼ì‹­ì‹œì˜¤'}")ë¥¼ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤.
4. í›„ì›ê¸ˆ ì˜ìˆ˜ì¦ ë°œê¸‰ ì•ˆë‚´ê°€ ìˆë‹¤ë©´ ì–¸ê¸‰í•˜ì‹­ì‹œì˜¤.
"""
                    print(f"ğŸ’° [StructureAgent] í›„ì› ì •ë³´ ì£¼ì…: {bank_name} {account_number} / {contact_number}")

            # ğŸ”´ [NEW] í–‰ì‚¬ ì•ˆë‚´ ì •ë³´ ì£¼ì…
            elif must_preserve and intent == 'event_announcement':
                event_date = must_preserve.get('eventDate')
                event_location = must_preserve.get('eventLocation')
                contact_number = must_preserve.get('contactNumber')
                cta_phrase = must_preserve.get('ctaPhrase')
                
                if event_date or event_location:
                    event_parts = []
                    if event_date:
                        event_parts.append(f"- ì¼ì‹œ: {event_date}")
                    if event_location:
                        event_parts.append(f"- ì¥ì†Œ: {event_location}")
                    if contact_number:
                        event_parts.append(f"- ë¬¸ì˜: {contact_number}")
                    
                    event_text = "\n".join(event_parts)
                    
                    context_injection += f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ“… [CRITICAL] í–‰ì‚¬ ì •ë³´ - ë³¸ë¬¸ì— ë°˜ë“œì‹œ í¬í•¨                 â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

**[í–‰ì‚¬ ì•ˆë‚´ ì •ë³´]**
{event_text}

ğŸ“Œ ìœ„ ì •ë³´ë¥¼ ë³¸ë¬¸ê³¼ ê²°ë¡ ë¶€ì— ëª…í™•íˆ í¬í•¨í•˜ì‹­ì‹œì˜¤.
"""
                    print(f"ğŸ“… [StructureAgent] í–‰ì‚¬ ì •ë³´ ì£¼ì…: {event_date} / {event_location}")

        # Warning Generation
        bio_warning = ""
        non_lawmaker_warn = generate_non_lawmaker_warning(
            self.is_current_lawmaker(user_profile),
            user_profile.get('politicalExperience'),
            params.get('authorBio')
        )
        if non_lawmaker_warn:
            bio_warning += non_lawmaker_warn + "\n\n"
        
        if params.get('authorBio') and '"' in params.get('authorBio', ''):
            bio_warning += """
ğŸš¨ [BIO ì¸ìš© ê·œì¹™ - ì ˆëŒ€ ì¤€ìˆ˜]
- Bioì— ìˆëŠ” **í°ë”°ì˜´í‘œ(" ")ë¡œ ë¬¶ì¸ ë¬¸ì¥**ì€ ì‚¬ìš©ìì˜ í•µì‹¬ ì„œì‚¬ì…ë‹ˆë‹¤.
- ì´ ë¬¸ì¥ì€ **í•œ ê¸€ìë„ ìˆ˜ì •í•˜ì§€ ë§ê³  ì›ë¬¸ ê·¸ëŒ€ë¡œ** ì¸ìš©í•˜ì‹­ì‹œì˜¤.
- íŠ¹íˆ AIê°€ ì„ì˜ë¡œ **ì‚¬ëŒ ì´ë¦„ìœ¼ë¡œ ë‹¨ì–´ë¥¼ ëŒ€ì²´**í•˜ëŠ” ê²ƒì€ ì ˆëŒ€ ê¸ˆì§€ì…ë‹ˆë‹¤.
  - âŒ ì˜ëª»ëœ ì˜ˆ: "ë²Œì¨ êµ­íšŒì˜ì› í–ˆì„ í…ë°" â†’ "ë²Œì¨ í™ê¸¸ë™ í–ˆì„ í…ë°"
  - âœ… ì˜¬ë°”ë¥¸ ì˜ˆ: "ë²Œì¨ êµ­íšŒì˜ì› í–ˆì„ í…ë°" (ì›ë¬¸ ê·¸ëŒ€ë¡œ)
"""

        # Modified Structure Enforcement: Dynamic based on stance_count
        stance_count = 0
        if context_analysis:
            stance_count = len(context_analysis.get('mustIncludeFromStance', []))

        # ë³¸ë¡  ì„¹ì…˜ ìˆ˜ ê²°ì •: ë¬´ì¡°ê±´ 3ê°œë¡œ ê³ ì • (ì‚¬ìš©ì ìš”ì²­ 5ë‹¨ êµ¬ì¡° ì¤€ìˆ˜: ë„ì…-ë³¸ë¡ 1-ë³¸ë¡ 2-ë³¸ë¡ 3-ê²°ë¡ )
        # ë‚´ìš©ì´ ë§ì•„ë„ 3ê°œë¡œ ì••ì¶•í•´ì•¼ ë¶„ëŸ‰(2000~2500ì)ì„ ë§ì¶œ ìˆ˜ ìˆìŒ.
        body_section_count = 3
        total_section_count = body_section_count + 2  # ë„ì…ë¶€ + ê²°ë¡ ë¶€
        min_total_chars = total_section_count * 350  # ì„¹ì…˜ë‹¹ ìµœì†Œ 350ì
        max_total_chars = total_section_count * 450  # ì„¹ì…˜ë‹¹ ìµœëŒ€ 450ì
        
        # ë™ì  ë³¸ë¡  êµ¬ì¡° ë¬¸ìì—´ ìƒì„±
        body_structure_lines = []
        for i in range(1, body_section_count + 1):
            body_structure_lines.append(f"{i+1}. ë³¸ë¡  {i} (1ì„¹ì…˜, 3ë¬¸ë‹¨, 350~450ì) - HTML <h2> ì†Œì œëª© í•„ìˆ˜")
        body_structure_str = "\\n".join(body_structure_lines)
        
        # ì§€ì—­ ì •ë³´ ì¶”ì¶œ - ë²”ìš©ì„± í™•ë³´ ë° ë™ì  ë³€ìˆ˜
        region_metro = user_profile.get('regionMetro', '')
        region_district = user_profile.get('regionDistrict', '')
        user_region = f"{region_metro} {region_district}".strip()
        if not user_region:
            user_region = "ì§€ì—­ ì‚¬íšŒ"
            
        structure_enforcement = f"""
<structure_guide mode="strict">
  <strategy>E-A-T (ì „ë¬¸ì„±-ê¶Œìœ„-ì‹ ë¢°) ì „ëµìœ¼ë¡œ ì‘ì„±</strategy>

  <volume warning="ìœ„ë°˜ ì‹œ ì‹œìŠ¤í…œ ì˜¤ë¥˜">
    <per_section min="350" max="450" recommended="400"/>
    <paragraphs_per_section>3ê°œ ë¬¸ë‹¨, ë¬¸ë‹¨ë‹¹ 3~4ë¬¸ì¥</paragraphs_per_section>
    <total sections="{total_section_count}" min="{min_total_chars}" max="{max_total_chars}"/>
    <caution>ë‚´ìš©ì´ ì•„ë¬´ë¦¬ ì¢‹ì•„ë„ ì„¹ì…˜ë‹¹ 450ì ì´ˆê³¼ ê¸ˆì§€. ê¸¸ì–´ì§€ë©´ ê³¼ê°íˆ ìš”ì•½.</caution>
  </volume>

  <expansion_guide name="ì„¹ì…˜ë³„ ì‘ì„± 4ë‹¨ê³„">
    ê° ë³¸ë¡  ì„¹ì…˜ì„ ì•„ë˜ íë¦„ìœ¼ë¡œ ì „ê°œí•˜ë˜, ê° ë‹¨ê³„ë¥¼ 1~2ë¬¸ì¥ìœ¼ë¡œ ì§§ê²Œ ì‘ì„± (ì¥í™©í•œ ì„œìˆ  ê¸ˆì§€)
    <step name="Why" sentences="1">ì‹œë¯¼ ê³ ì¶© ì§„ë‹¨</step>
    <step name="How+Expertise" sentences="2">í•´ê²°ì±… + Bio ì¸ìš© [ì „ë¬¸ì„±]</step>
    <step name="Authority" sentences="1">ì‹¤í–‰ ëŠ¥ë ¥ ì¦ëª… [ê¶Œìœ„]</step>
    <step name="Effect+Trust" sentences="2">ë³€í™”ë  {user_region}ì˜ ëª¨ìŠµ + ì§„ì •ì„± [ì‹ ë¢°]</step>
  </expansion_guide>

  <sections total="{total_section_count}">
    <intro paragraphs="3" chars="400" heading="ì—†ìŒ">
      <p>1ë¬¸ë‹¨: ì¸ì‚¿ë§ (&lt;p&gt;ì•ˆë…•í•˜ì„¸ìš”, OOOì…ë‹ˆë‹¤.&lt;/p&gt;)</p>
      <p>2ë¬¸ë‹¨: ì£¼ì œ ë„ì… ë° ë°°ê²½ ì„¤ëª…</p>
      <p>3ë¬¸ë‹¨: ê¸€ì˜ ë°©í–¥ì„± ì œì‹œ</p>
    </intro>
    {body_structure_str}
    <conclusion order="{total_section_count}" paragraphs="3" chars="400" heading="h2 í•„ìˆ˜"/>
  </sections>

  <h2_strategy name="ì†Œì œëª© ì‘ì„± ì „ëµ (AEO+SEO)">
    <type name="ì§ˆë¬¸í˜•" strength="AEO ìµœê°•">ì²­ë…„ ê¸°ë³¸ì†Œë“, ì‹ ì²­ ë°©ë²•ì€?</type>
    <type name="ëª…ì‚¬í˜•" strength="SEO ê¸°ë³¸">ë¶„ë‹¹êµ¬ ì •ìë™ ì£¼ì°¨ì¥ ì‹ ì„¤ ìœ„ì¹˜</type>
    <type name="ë°ì´í„°" strength="ì‹ ë¢°ì„±">2025ë…„ ìƒë°˜ê¸° 5ëŒ€ ì£¼ìš” ì„±ê³¼</type>
    <type name="ì ˆì°¨" strength="ì‹¤ìš©ì„±">ì²­ë…„ ê¸°ë³¸ì†Œë“ ì‹ ì²­ 3ë‹¨ê³„ ì ˆì°¨</type>
    <type name="ë¹„êµ" strength="ì°¨ë³„í™”">ê¸°ì¡´ ì •ì±… ëŒ€ë¹„ ê°œì„ ëœ 3ê°€ì§€</type>
    <banned>ì¶”ìƒì  í‘œí˜„("ë…¸ë ¥", "ì—´ì „", "ë§ˆìŒ"), ëª¨í˜¸í•œ ì œëª©("ì •ì±… ì•ˆë‚´", "ì†Œê°œ"), ì„œìˆ ì–´ í¬í•¨("~ì— ëŒ€í•œ ì„¤ëª…")</banned>
  </h2_strategy>

  <mandatory_rules>
    <rule id="html_tags">ì†Œì œëª©ì€ &lt;h2&gt;, ë¬¸ë‹¨ì€ &lt;p&gt; íƒœê·¸ë§Œ ì‚¬ìš© (ë§ˆí¬ë‹¤ìš´ ** ê¸ˆì§€)</rule>
    <rule id="no_slogan_repeat" severity="critical">ì…ì¥ë¬¸ì˜ ë§ºìŒë§/ìŠ¬ë¡œê±´ì„ ê° ì„¹ì…˜ ëë§ˆë‹¤ ë°˜ë³µ ê¸ˆì§€. ëª¨ë“  í˜¸ì†Œì™€ ë‹¤ì§ì€ ë§¨ ë§ˆì§€ë§‰ ê²°ë¡ ë¶€ì—ë§Œ.</rule>
    <rule id="sentence_completion">ë¬¸ì¥ì€ ì˜¬ë°”ë¥¸ ì¢…ê²° ì–´ë¯¸(~ì…ë‹ˆë‹¤, ~í•©ë‹ˆë‹¤, ~ì‹œì˜¤)ë¡œ ëë‚´ì•¼ í•¨. ê³ ì˜ì  ì˜¤íƒ€/ì˜ë¦° ë¬¸ì¥ ê¸ˆì§€.</rule>
    <rule id="keyword_per_section">ê° ì„¹ì…˜ë§ˆë‹¤ í‚¤ì›Œë“œ 1ê°œ ì´ìƒ í¬í•¨</rule>
    <rule id="separate_pledges">ë³¸ë¡  1, 2, 3ì€ ê°ê° ë‹¤ë¥¸ ì£¼ì œ/ê³µì•½ì„ ë‹¤ë£° ê²ƒ</rule>
    <rule id="verb_diversity" severity="critical">ê°™ì€ ë™ì‚¬(ì˜ˆ: "ë˜ì§€ë©´ì„œ")ë¥¼ ì›ê³  ì „ì²´ì—ì„œ 3íšŒ ì´ìƒ ì‚¬ìš© ê¸ˆì§€. ë™ì˜ì–´ êµì²´: ì œì‹œí•˜ë©°, ì•½ì†í•˜ë©°, ì—´ë©°, ë³´ì—¬ë“œë¦¬ë©° ë“±.</rule>
    <rule id="slogan_once">ìºì¹˜í”„ë ˆì´ì¦ˆ("ì²­ë…„ì´ ëŒì•„ì˜¤ëŠ” ë¶€ì‚°")ë‚˜ ë¹„ìœ ("ì•„ì‹œì•„ì˜ ì‹±ê°€í¬ë¥´")ëŠ” ê²°ë¡ ë¶€ 1íšŒë§Œ. ë‹¤ë¥¸ ì„¹ì…˜ì—ì„œëŠ” ë³€í˜• ì‚¬ìš©.</rule>
    <rule id="natural_keyword">í‚¤ì›Œë“œë§Œìœ¼ë¡œ êµ¬ì„±ëœ ë‹¨ë… ë¬¸ì¥ ê¸ˆì§€. ì• ë¬¸ë‹¨ê³¼ ì—°ê²°ì–´ë¡œ ì´ì–´ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ë°°ì¹˜.</rule>
    <rule id="causal_clarity">ì„±ê³¼ ì–¸ê¸‰ ì‹œ ë³¸ì¸ì˜ êµ¬ì²´ì  ì—­í• /ì§ì±… ëª…ì‹œ. "40% ë“í‘œìœ¨ì„ ì´ëŒì–´ëƒˆë‹¤" â†’ "ì‹œë‹¹ìœ„ì›ì¥ìœ¼ë¡œì„œ ì§€ì—­ ì¡°ì§ì„ ì´ê´„í•˜ë©° 40% ë“í‘œìœ¨ ë‹¬ì„±ì— ê¸°ì—¬í–ˆìŠµë‹ˆë‹¤"</rule>
  </mandatory_rules>

  <constraints warning="ìœ„ë°˜ ì‹œ ìë™ ë°˜ë ¤">
    <max_chars>{max_total_chars}</max_chars>
    <min_chars>{min_total_chars}</min_chars>
    <no_repeat>ê°™ì€ ë¬¸ì¥, ê°™ì€ í‘œí˜„ ë°˜ë³µ ê¸ˆì§€ (íŠ¹íˆ "~ë°”ëë‹ˆë‹¤" ë°˜ë³µ ê¸ˆì§€)</no_repeat>
    <html>ë¬¸ë‹¨ì€ &lt;p&gt;...&lt;/p&gt;, ì†Œì œëª©ì€ &lt;h2&gt;...&lt;/h2&gt;ë§Œ ì‚¬ìš©</html>
    <separate_pledges>ì„œë¡œ ë‹¤ë¥¸ ê³µì•½/ì •ì±…ì€ í•˜ë‚˜ì˜ ë³¸ë¡ ì— í•©ì¹˜ì§€ ë§ ê²ƒ</separate_pledges>
  </constraints>

  <output_format>í…œí”Œë¦¿ì—ì„œ ì§€ì‹œí•œ XML íƒœê·¸(title, content, hashtags)ë§Œ ì¶œë ¥. output ë˜í¼ë‚˜ ë§ˆí¬ë‹¤ìš´ ì½”ë“œë¸”ë¡ ê¸ˆì§€.</output_format>
</structure_guide>
"""

        # SEO ì§€ì¹¨ ìƒì„±
        seo_instruction = build_seo_instruction({
            'keywords': params.get('userKeywords', []),
            'targetWordCount': params.get('targetWordCount', 2000)
        })

        # ì„ ê±°ë²• ì¤€ìˆ˜ ì§€ì¹¨ ìƒì„±
        user_status = user_profile.get('status', 'ì¤€ë¹„')
        election_instruction = get_prompt_instruction(user_status)

        return f"""
{template_prompt}

{params.get('partyStanceGuide') or ''}

{seo_instruction}

{election_instruction}

{ref_section}

{context_injection}

{bio_warning}

{structure_enforcement}
""".strip()

    def build_author_bio(self, user_profile: Dict) -> tuple[str, str]:
        # ë°©ì–´ ì½”ë“œ - listë¡œ ì „ë‹¬ë˜ëŠ” ê²½ìš° ë°©ì–´
        if not isinstance(user_profile, dict):
            user_profile = {}

        name = user_profile.get('name', 'ì‚¬ìš©ì')
        party_name = user_profile.get('partyName', '')
        current_title = user_profile.get('customTitle') or user_profile.get('position', '')
        basic_bio = " ".join(filter(None, [party_name, current_title, name]))

        career = user_profile.get('careerSummary') or user_profile.get('bio', '')
        slogan = f'"{user_profile.get("slogan")}"' if user_profile.get('slogan') else ''
        donation = f'[í›„ì› ì•ˆë‚´] {user_profile.get("donationInfo")}' if user_profile.get('donationInfo') else ''

        return f"{basic_bio}\n{career}\n{slogan}\n{donation}".strip(), name

    def is_current_lawmaker(self, user_profile: Dict) -> bool:
        # ë°©ì–´ ì½”ë“œ - listë¡œ ì „ë‹¬ë˜ê±°ë‚˜ Noneì¸ ê²½ìš° ë°©ì–´
        if not user_profile or not isinstance(user_profile, dict):
            return False
        status = user_profile.get('status', '')
        position = user_profile.get('position', '')
        title = user_profile.get('customTitle', '')

        elected_keywords = ['ì˜ì›', 'êµ¬ì²­ì¥', 'êµ°ìˆ˜', 'ì‹œì¥', 'ë„ì§€ì‚¬', 'êµìœ¡ê°']
        text_to_check = status + position + title
        return any(k in text_to_check for k in elected_keywords)

    def parse_response(self, response: str) -> Dict[str, str]:
        if not response:
            return {'content': '', 'title': ''}
        
        # XML Tag Extraction
        try:
            # Title extraction
            title_match = re.search(r'<title>(.*?)</title>', response, re.DOTALL | re.IGNORECASE)
            title = title_match.group(1).strip() if title_match else ''
            
            # Content extraction
            content_match = re.search(r'<content>(.*?)</content>', response, re.DOTALL | re.IGNORECASE)
            content = content_match.group(1).strip() if content_match else ''
            
            if not content:
                # Fallback: try to find just HTML tags if XML tags are missing
                print('âš ï¸ [StructureAgent] XML íƒœê·¸ ëˆ„ë½, HTML ì§ì ‘ ì¶”ì¶œ ì‹œë„')
                html_block_match = re.search(r'<(?:p|h[23])[^>]*>[\s\S]*<\/(?:p|h[23])>', response, re.IGNORECASE)
                if html_block_match:
                    content = html_block_match.group(0)
                else:
                    content = response # ìµœí›„ë‹¨: ì „ì²´ í…ìŠ¤íŠ¸
            
            print(f"âœ… [StructureAgent] íŒŒì‹± ì„±ê³µ: content={len(content)}ì")
            return {'content': content, 'title': title}
            
        except Exception as e:
            print(f"âš ï¸ [StructureAgent] íŒŒì‹± ì—ëŸ¬: {str(e)}")
            return {'content': response, 'title': ''}

    def validate_output(self, content: str, target_word_count: int) -> Dict:
        if not content:
            return {'passed': False, 'reason': 'ë‚´ìš© ì—†ìŒ', 'feedback': 'ë‚´ìš©ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.'}
        
        plain_length = len(strip_html(content))
        
        # ë¶„ëŸ‰ ê·œì¹™: 5~7ì„¹ì…˜ Ã— (350~450)ì = 1750~3150ì
        # ë™ì  êµ¬ì¡°ì— ë§ì¶° ì—¬ìœ ìˆê²Œ ì„¤ì •
        min_length = 1750  # 5ì„¹ì…˜ Ã— 350ì
        max_length = 3150  # 7ì„¹ì…˜ Ã— 450ì

        if plain_length < min_length:
            deficit = min_length - plain_length
            return {
                'passed': False,
                'reason': f"ë¶„ëŸ‰ ë¶€ì¡± ({plain_length}ì < {min_length}ì)",
                'feedback': f"í˜„ì¬ ë¶„ëŸ‰({plain_length}ì)ì´ ìµœì†Œ ê¸°ì¤€({min_length}ì)ë³´ë‹¤ {deficit}ì ë¶€ì¡±í•©ë‹ˆë‹¤. ê° ì„¹ì…˜ì„ 400ì ì•ˆíŒìœ¼ë¡œ ì‘ì„±í•˜ê³ , ë¬¸ë‹¨ë‹¹ 120~150ìë¥¼ ìœ ì§€í•˜ì‹­ì‹œì˜¤."
            }
        
        if plain_length > max_length:
            excess = plain_length - max_length
            return {
                'passed': False,
                'reason': f"ë¶„ëŸ‰ ì´ˆê³¼ ({plain_length}ì > {max_length}ì)",
                'feedback': f"í˜„ì¬ ë¶„ëŸ‰({plain_length}ì)ì´ ìµœëŒ€ ê¸°ì¤€({max_length}ì)ì„ {excess}ì ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ê° ì„¹ì…˜ì„ 400ì ì•ˆíŒìœ¼ë¡œ ì••ì¶•í•˜ê³ , ë¶ˆí•„ìš”í•œ ë°˜ë³µì´ë‚˜ ì‚¬ì¡±ì„ ì œê±°í•˜ì‹­ì‹œì˜¤. 7ê°œ ì„¹ì…˜ì„ ë„˜ê¸°ì§€ ë§ˆì‹­ì‹œì˜¤."
            }
        
        h2_count = len(re.findall(r'<h2>', content, re.IGNORECASE))
        if h2_count < 4:
            return {
                'passed': False,
                'reason': f"ì†Œì œëª© ë¶€ì¡± (í˜„ì¬ {h2_count}ê°œ)",
                'feedback': "ì†Œì œëª©(<h2>)ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ë°˜ë“œì‹œ 4ê°œ ì´ìƒì˜ ì†Œì œëª©(ë³¸ë¡  3ê°œ + ê²°ë¡  1ê°œ ë“±)ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤."
            }
        
        if h2_count > 6:
            return {
                'passed': False,
                'reason': f"ì†Œì œëª© ê³¼ë‹¤ (í˜„ì¬ {h2_count}ê°œ)",
                'feedback': "ì†Œì œëª©(<h2>)ì´ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤. ìµœëŒ€ 6ê°œ(ë³¸ë¡  5ê°œ + ê²°ë¡  1ê°œ)ë¥¼ ë„˜ê¸°ì§€ ë§ˆì‹­ì‹œì˜¤."
            }

        p_count = len(re.findall(r'<p>', content, re.IGNORECASE))
        expected_min_p = (h2_count + 1) * 3  # ë„ì…ë¶€ í¬í•¨, ì„¹ì…˜ë‹¹ 3ë¬¸ë‹¨
        expected_max_p = (h2_count + 1) * 4  # ì—¬ìœ ë¶„
        
        if p_count < expected_min_p:
             return {
                'passed': False,
                'reason': f"ë¬¸ë‹¨ ìˆ˜ ë¶€ì¡± (í˜„ì¬ {p_count}ê°œ, í•„ìš” {expected_min_p}ê°œ ì´ìƒ)",
                'feedback': f"ë¬¸ë‹¨ ìˆ˜ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤. {h2_count + 1}ê°œ ì„¹ì…˜ì— ëŒ€í•´ ì„¹ì…˜ë‹¹ 3ê°œ ë¬¸ë‹¨ì”© ì´ {expected_min_p}ê°œ ì´ìƒ í•„ìš”í•©ë‹ˆë‹¤."
            }

        return {'passed': True}
