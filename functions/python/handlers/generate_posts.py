"""
generatePosts Python onCall handler.

Node `handlers/posts.js`ì˜ generatePosts ì—”íŠ¸ë¦¬ ì—­í• ì„ Pythonìœ¼ë¡œ ì´ê´€í•œë‹¤.
í•µì‹¬ ìƒì„± ë¡œì§ì€ ê¸°ì¡´ Step Functions íŒŒì´í”„ë¼ì¸(`pipeline_start` + Cloud Tasks)ì„ ì¬ì‚¬ìš©í•œë‹¤.
"""

from __future__ import annotations

import json
import logging
import re
import time
from collections.abc import Iterable
from dataclasses import dataclass
from datetime import datetime
from typing import Any, Dict, Optional

from firebase_admin import firestore
from firebase_functions import https_fn

from services.posts.profile_loader import (
    get_or_create_session,
    increment_session_attempts,
    load_user_profile,
)

logger = logging.getLogger(__name__)

DEFAULT_TARGET_WORD_COUNT = 2000
MAX_POLL_TIME_SECONDS = 10 * 60
POLL_INTERVAL_SECONDS = 0.8

CATEGORY_MIN_WORD_COUNT = {
    "local-issues": 2000,
    "policy-proposal": 2000,
    "activity-report": 2000,
    "current-affairs": 2000,
    "daily-communication": 2000,
}

# í”„ë¡ íŠ¸ ë¡œë”© ì˜¤ë²„ë ˆì´ê°€ ìˆœí™˜ ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•˜ëŠ” ê¸°ì¤€ í‚¤.
LOADING_STAGE_STRUCTURE = "êµ¬ì¡° ì„¤ê³„ ë° ì´ˆì•ˆ ì‘ì„± ì¤‘"
LOADING_STAGE_BODY = "ë³¸ë¬¸ ì‘ì„± ì¤‘"
LOADING_STAGE_SEO = "ê²€ìƒ‰ ë…¸ì¶œ ìµœì í™”(SEO) ì¤‘"

_STEP_NAME_TO_LOADING_STAGE = {
    "structureagent": LOADING_STAGE_STRUCTURE,
    "writeragent": LOADING_STAGE_STRUCTURE,
    "keywordinjectoragent": LOADING_STAGE_BODY,
    "styleagent": LOADING_STAGE_BODY,
    "complianceagent": LOADING_STAGE_BODY,
    "seoagent": LOADING_STAGE_SEO,
    "titleagent": LOADING_STAGE_SEO,
}


@dataclass
class ApiError(Exception):
    code: str
    message: str

    def __str__(self) -> str:
        return self.message


class ProgressTracker:
    """Firestore generation_progress ë™ê¸° ì—…ë°ì´íŠ¸."""

    def __init__(self, session_id: str):
        self.session_id = str(session_id or "").strip()
        self.ref = firestore.client().collection("generation_progress").document(self.session_id)

    def update(self, step: int, progress: int, message: str, error: bool = False) -> None:
        payload = {
            "step": int(step),
            "progress": int(progress),
            "message": str(message or ""),
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "updatedAt": int(time.time() * 1000),
        }
        if error:
            payload["error"] = True
        try:
            self.ref.set(payload, merge=True)
        except Exception as exc:
            logger.warning("ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: %s", exc)

    def step_preparing(self) -> None:
        self.update(1, 10, "ì¤€ë¹„ ì¤‘...")

    def step_collecting(self) -> None:
        self.update(2, 25, "ìë£Œ ìˆ˜ì§‘ ì¤‘...")

    def step_generating(self) -> None:
        # í”„ë¡ íŠ¸ STEP_MESSAGES í‚¤ì™€ ë™ì¼í•œ ê°’ìœ¼ë¡œ ê³ ì •í•´ ëœë¤ ìˆœí™˜ì„ í™œì„±í™”í•œë‹¤.
        self.update(3, 50, LOADING_STAGE_STRUCTURE)

    def step_validating(self) -> None:
        self.update(4, 80, "í’ˆì§ˆ ê²€ì¦ ì¤‘...")

    def step_finalizing(self) -> None:
        self.update(5, 95, "ë§ˆë¬´ë¦¬ ì¤‘...")

    def complete(self) -> None:
        self.update(5, 100, "ì™„ë£Œ")

    def error(self, error_message: str) -> None:
        self.update(-1, 0, f"ì˜¤ë¥˜: {error_message}", error=True)


class _InternalRequest:
    """
    pipeline_start.handle_start ì¬ì‚¬ìš©ì„ ìœ„í•œ ìµœì†Œ Request ì–´ëŒ‘í„°.
    """

    def __init__(self, payload: Dict[str, Any], headers: Optional[Dict[str, str]] = None):
        self._payload = payload
        self.headers = headers or {}

    def get_json(self, silent: bool = True) -> Dict[str, Any]:
        _ = silent
        return self._payload


def _safe_dict(value: Any) -> Dict[str, Any]:
    if isinstance(value, dict):
        return value
    return {}


def _normalize_step_name(value: Any) -> str:
    if value is None:
        return ""
    if isinstance(value, str):
        return value.strip()
    if isinstance(value, Iterable) and not isinstance(value, (bytes, bytearray)):
        return " ".join(str(item).strip() for item in value if str(item).strip())
    return str(value).strip()


def _to_loading_stage_message(raw_step_name: Any) -> str:
    step_name = _normalize_step_name(raw_step_name)
    normalized = re.sub(r"\s+", "", step_name).lower()
    if not normalized:
        return LOADING_STAGE_BODY

    stage_message = _STEP_NAME_TO_LOADING_STAGE.get(normalized)
    if stage_message:
        return stage_message

    # step ëª…ì¹­ì´ ì¼ë¶€ ë³€ê²½ë˜ì–´ë„ í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ í”„ë¡ íŠ¸ ë‹¨ê³„ì™€ ë™ê¸°í™”í•œë‹¤.
    if "seo" in normalized or "title" in normalized:
        return LOADING_STAGE_SEO
    if "structure" in normalized or "writer" in normalized:
        return LOADING_STAGE_STRUCTURE
    if "keyword" in normalized or "style" in normalized or "compliance" in normalized:
        return LOADING_STAGE_BODY
    return LOADING_STAGE_BODY


def _to_int(value: Any, default: int) -> int:
    try:
        if value is None:
            return default
        if isinstance(value, bool):
            return int(value)
        if isinstance(value, (int, float)):
            return int(value)
        text = str(value).strip()
        if not text:
            return default
        return int(float(text))
    except Exception:
        return default


def _strip_html(text: str) -> str:
    return re.sub(r"<[^>]*>", "", str(text or ""))


def _normalize_keywords(raw_keywords: Any) -> list[str]:
    if isinstance(raw_keywords, list):
        return [str(item).strip() for item in raw_keywords if str(item).strip()]
    if isinstance(raw_keywords, str):
        return [part.strip() for part in raw_keywords.split(",") if part.strip()]
    return []


def _map_api_error(code: str, message: str) -> ApiError:
    normalized = str(code or "").strip().upper()
    mapping = {
        "INVALID_INPUT": "invalid-argument",
        "INVALID_ARGUMENT": "invalid-argument",
        "UNAUTHENTICATED": "unauthenticated",
        "PERMISSION_DENIED": "permission-denied",
        "FAILED_PRECONDITION": "failed-precondition",
        "RESOURCE_EXHAUSTED": "resource-exhausted",
        "NOT_FOUND": "not-found",
        "INTERNAL_ERROR": "internal",
        "EXECUTION_ERROR": "internal",
    }
    return ApiError(mapping.get(normalized, "internal"), message or "ìš”ì²­ ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")


def _today_key() -> str:
    now = datetime.now()
    return f"{now.year:04d}-{now.month:02d}-{now.day:02d}"


def _month_key() -> str:
    now = datetime.now()
    return f"{now.year:04d}-{now.month:02d}"


def _clear_active_session(uid: str) -> None:
    try:
        firestore.client().collection("users").document(uid).update(
            {"activeGenerationSession": firestore.DELETE_FIELD}
        )
    except Exception as exc:
        logger.warning("ê¸°ì¡´ ì„¸ì…˜ ì‚­ì œ ì‹¤íŒ¨(ë¬´ì‹œ): %s", exc)


def _calc_daily_limit_warning(user_profile: Dict[str, Any]) -> bool:
    daily_usage = _safe_dict(user_profile.get("dailyUsage"))
    today = _today_key()
    return _to_int(daily_usage.get(today), 0) >= 3


def _apply_usage_updates_after_success(
    uid: str,
    *,
    is_admin: bool,
    is_tester: bool,
    session: Dict[str, Any],
) -> None:
    if is_admin:
        return
    if not bool(session.get("isNewSession")):
        return

    db = firestore.client()
    user_ref = db.collection("users").document(uid)
    user_doc = user_ref.get()
    user_data = user_doc.to_dict() if user_doc.exists else {}
    user_data = _safe_dict(user_data)

    subscription_status = str(user_data.get("subscriptionStatus") or "trial").strip().lower()
    current_month_key = _month_key()
    update_data: Dict[str, Any] = {}

    # system/config testMode ì¡°íšŒ
    test_mode = False
    try:
        system_doc = db.collection("system").document("config").get()
        if system_doc.exists:
            system_data = _safe_dict(system_doc.to_dict())
            test_mode = bool(system_data.get("testMode") is True)
    except Exception:
        test_mode = False

    if is_tester or subscription_status == "active":
        update_data[f"monthlyUsage.{current_month_key}.generations"] = firestore.Increment(1)
    elif test_mode:
        update_data[f"monthlyUsage.{current_month_key}.generations"] = firestore.Increment(1)
    elif subscription_status == "trial":
        current_remaining = _to_int(
            user_data.get("generationsRemaining", user_data.get("trialPostsRemaining", 0)),
            0,
        )
        if current_remaining > 0:
            update_data["generationsRemaining"] = firestore.Increment(-1)

    if update_data:
        user_ref.update(update_data)


def _extract_start_payload(
    uid: str,
    data: Dict[str, Any],
    *,
    topic: str,
    category: str,
    target_word_count: int,
    user_keywords: list[str],
    pipeline_route: str,
) -> Dict[str, Any]:
    payload = dict(data)
    payload["topic"] = topic
    payload["category"] = category
    payload["subCategory"] = str(data.get("subCategory") or "")
    payload["targetWordCount"] = int(target_word_count)
    payload["uid"] = uid
    payload["userId"] = uid
    payload["pipeline"] = pipeline_route
    payload["keywords"] = user_keywords
    payload["userKeywords"] = user_keywords
    return payload


def _call_pipeline_start(start_payload: Dict[str, Any]) -> str:
    from handlers.pipeline_start import handle_start

    internal_req = _InternalRequest(payload={"data": start_payload}, headers={"X-User-Id": str(start_payload.get("uid") or "")})
    response = handle_start(internal_req)
    status_code = int(getattr(response, "status_code", 500))
    body_text = ""
    try:
        body_text = response.get_data(as_text=True)
    except Exception:
        body_text = ""

    payload = {}
    if body_text:
        try:
            payload = json.loads(body_text)
        except Exception:
            payload = {}

    if status_code >= 400:
        message = str(payload.get("error") or "íŒŒì´í”„ë¼ì¸ ì‹œì‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        raise _map_api_error(str(payload.get("code") or "INTERNAL_ERROR"), message)

    job_id = str(payload.get("jobId") or "").strip()
    if not job_id:
        raise ApiError("internal", "íŒŒì´í”„ë¼ì¸ Job IDë¥¼ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    return job_id


def _poll_pipeline(job_id: str, progress: ProgressTracker) -> Dict[str, Any]:
    from services.job_manager import JobManager

    job_manager = JobManager()
    started_at = time.time()
    last_message = ""

    while time.time() - started_at < MAX_POLL_TIME_SECONDS:
        time.sleep(POLL_INTERVAL_SECONDS)
        job_data = job_manager.get_job(job_id)
        if not job_data:
            continue

        status = str(job_data.get("status") or "running")
        total_steps = _to_int(job_data.get("totalSteps"), 1)
        steps = _safe_dict(job_data.get("steps"))
        completed_steps = 0
        for step_val in steps.values():
            step_obj = _safe_dict(step_val)
            if step_obj.get("status") == "completed":
                completed_steps += 1

        percentage = round((completed_steps / max(total_steps, 1)) * 100, 1)
        current_step_index = str(job_data.get("currentStep", 0))
        current_step_obj = _safe_dict(steps.get(current_step_index))
        current_step_name = _normalize_step_name(current_step_obj.get("name") or "íŒŒì´í”„ë¼ì¸")

        if status == "running":
            current_percentage = int(round(30 + percentage * 0.5))
            message = _to_loading_stage_message(current_step_name)
            if message != last_message:
                progress.update(3, current_percentage, message)
                last_message = message
            continue

        if status == "completed":
            result = _safe_dict(job_data.get("result"))
            if not result:
                raise ApiError("internal", "íŒŒì´í”„ë¼ì¸ ê²°ê³¼ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
            return result

        if status == "failed":
            error_obj = _safe_dict(job_data.get("error"))
            step = str(error_obj.get("step") or current_step_name or "unknown")
            message = str(error_obj.get("message") or "íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨")
            raise ApiError("internal", f"Pipeline failed at step {step}: {message}")

    raise ApiError("deadline-exceeded", "Pipeline timeout: 10ë¶„ ë‚´ì— ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")


def _ensure_user(uid: str) -> None:
    if not uid:
        raise ApiError("unauthenticated", "ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.")


def _topic_and_category(data: Dict[str, Any]) -> tuple[str, str]:
    topic = str(data.get("prompt") or data.get("topic") or "").strip()
    if not topic:
        raise ApiError("invalid-argument", "ì£¼ì œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    category = str(data.get("category") or "daily-communication").strip() or "daily-communication"
    return topic, category


def _target_word_count(data: Dict[str, Any], category: str) -> int:
    requested = _to_int(data.get("wordCount"), DEFAULT_TARGET_WORD_COUNT)
    minimum = _to_int(CATEGORY_MIN_WORD_COUNT.get(category), DEFAULT_TARGET_WORD_COUNT)
    return max(requested, minimum)


def _calc_min_required_chars(target_word_count: int, stance_count: int = 0) -> int:
    # StructureAgent._build_length_specì™€ ë™ì¼ ê¸°ì¤€(ì™„í™” ì•„ë‹˜)
    target_chars = max(1600, min(int(target_word_count), 3200))
    total_sections = round(target_chars / 400)
    total_sections = max(5, min(7, total_sections))
    if stance_count > 0:
        total_sections = max(total_sections, min(7, stance_count + 2))

    per_section_recommended = max(360, min(420, round(target_chars / total_sections)))
    per_section_min = max(320, per_section_recommended - 50)
    return max(int(target_chars * 0.88), total_sections * per_section_min)


def _extract_stance_count(pipeline_result: Dict[str, Any]) -> int:
    context_analysis = pipeline_result.get("contextAnalysis")
    if not isinstance(context_analysis, dict):
        return 0
    must_include = context_analysis.get("mustIncludeFromStance")
    if not isinstance(must_include, list):
        return 0
    return len([item for item in must_include if item])


def _validate_keyword_gate(keyword_validation: Dict[str, Any]) -> tuple[bool, str]:
    if not isinstance(keyword_validation, dict) or not keyword_validation:
        return False, "í‚¤ì›Œë“œ ê²€ì¦ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."

    failures: list[str] = []
    for keyword, info in keyword_validation.items():
        if not isinstance(info, dict):
            continue
        status = str(info.get("status") or "").strip().lower()
        count = _to_int(info.get("count"), 0)
        expected = _to_int(info.get("expected"), 0)
        max_count = _to_int(info.get("max"), 0)
        if status == "insufficient":
            failures.append(f"\"{keyword}\" ë¶€ì¡± ({count}/{expected})")
        elif status == "spam_risk":
            failures.append(f"\"{keyword}\" ê³¼ë‹¤ ({count}/{max_count})")

    if failures:
        return False, "; ".join(failures)
    return True, ""


def _choose_pipeline_route(raw_route: Any, *, is_admin: bool, is_tester: bool) -> str:
    route = str(raw_route or "modular").strip() or "modular"
    if route == "highQuality":
        if is_admin or is_tester:
            return "modular"
        return "standard"
    return route


def handle_generate_posts_call(req: https_fn.CallableRequest) -> Dict[str, Any]:
    started_ms = int(time.time() * 1000)
    uid = req.auth.uid if req.auth else ""
    _ensure_user(uid)

    data = req.data if isinstance(req.data, dict) else {}
    if isinstance(data.get("data"), dict):
        data = data["data"]

    topic, category = _topic_and_category(data)
    target_word_count = _target_word_count(data, category)

    progress_session_id = str(data.get("progressSessionId") or f"{uid}_{int(time.time() * 1000)}")
    progress = ProgressTracker(progress_session_id)
    progress.step_preparing()

    # í”„ë¡œí•„ ë¡œë“œ (ê¶Œí•œ/ì„¸ì…˜/ê²½ê³ /ì‘ë‹µ ë©”íƒ€ë°ì´í„°ìš©)
    profile_bundle = load_user_profile(uid, category=category, topic=topic, options={"strictSourceOnly": True})
    user_profile = _safe_dict(profile_bundle.get("userProfile"))
    is_admin = bool(profile_bundle.get("isAdmin") is True)
    is_tester = bool(profile_bundle.get("isTester") is True)
    daily_limit_warning = _calc_daily_limit_warning(user_profile)

    requested_session_id = str(data.get("sessionId") or "").strip()
    if not requested_session_id:
        _clear_active_session(uid)

    session = get_or_create_session(uid, is_admin=is_admin, is_tester=is_tester, category=category, topic=topic)
    session = _safe_dict(session)
    attempts = _to_int(session.get("attempts"), 0)
    max_attempts = _to_int(session.get("maxAttempts"), 3)
    if attempts >= max_attempts:
        raise ApiError(
            "resource-exhausted",
            f"ìµœëŒ€ {max_attempts}íšŒê¹Œì§€ë§Œ ì¬ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ ì›ê³ ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.",
        )

    progress.step_collecting()
    progress.step_generating()

    user_keywords = _normalize_keywords(data.get("keywords"))
    pipeline_route = _choose_pipeline_route(data.get("pipeline"), is_admin=is_admin, is_tester=is_tester)
    start_payload = _extract_start_payload(
        uid,
        data,
        topic=topic,
        category=category,
        target_word_count=target_word_count,
        user_keywords=user_keywords,
        pipeline_route=pipeline_route,
    )

    job_id = _call_pipeline_start(start_payload)
    pipeline_result = _poll_pipeline(job_id, progress)

    generated_content = str(pipeline_result.get("content") or "").strip()
    if not generated_content:
        raise ApiError("internal", "ì›ê³  ìƒì„± ì‹¤íŒ¨ - ì½˜í…ì¸ ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    generated_title = str(pipeline_result.get("title") or topic).strip() or topic
    keyword_validation = _safe_dict(pipeline_result.get("keywordValidation"))
    seo_passed = pipeline_result.get("seoPassed")
    compliance_passed = pipeline_result.get("compliancePassed")
    writing_method = str(pipeline_result.get("writingMethod") or pipeline_route or "modular")
    keyword_counts = pipeline_result.get("keywordCounts") if isinstance(pipeline_result.get("keywordCounts"), dict) else {}
    word_count = _to_int(pipeline_result.get("wordCount"), len(_strip_html(generated_content)))
    stance_count = _extract_stance_count(pipeline_result)
    min_required_chars = _calc_min_required_chars(target_word_count, stance_count)
    if word_count < min_required_chars:
        raise ApiError(
            "internal",
            f"ìµœì¢… ì›ê³  ë¶„ëŸ‰ ë¶€ì¡± ({word_count}ì < {min_required_chars}ì)",
        )
    keyword_gate_ok, keyword_gate_msg = _validate_keyword_gate(keyword_validation)
    if not keyword_gate_ok:
        raise ApiError(
            "internal",
            f"í‚¤ì›Œë“œ ê¸°ì¤€ ë¯¸ì¶©ì¡±: {keyword_gate_msg}",
        )

    # ìƒì„± ì„±ê³µ í›„ attempts / ì‚¬ìš©ëŸ‰ ì—…ë°ì´íŠ¸
    session = increment_session_attempts(uid, session, is_admin=is_admin, is_tester=is_tester)
    session = _safe_dict(session)
    _apply_usage_updates_after_success(uid, is_admin=is_admin, is_tester=is_tester, session=session)

    progress.step_validating()
    progress.step_finalizing()
    progress.complete()

    generated_at = datetime.utcnow().isoformat() + "Z"
    now_ms = int(time.time() * 1000)
    draft_data = {
        "id": f"draft_{now_ms}",
        "title": generated_title,
        "content": generated_content,
        "wordCount": word_count,
        "category": category,
        "subCategory": str(data.get("subCategory") or ""),
        "keywords": data.get("keywords") or "",
        "generatedAt": generated_at,
    }

    attempts_after = _to_int(session.get("attempts"), attempts + 1)
    can_regenerate = attempts_after < max_attempts

    message = "ì›ê³ ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤"
    if daily_limit_warning:
        message += (
            "\n\nâš ï¸ í•˜ë£¨ 3íšŒ ì´ìƒ ì›ê³ ë¥¼ ìƒì„±í•˜ì…¨ìŠµë‹ˆë‹¤. ë„¤ì´ë²„ ë¸”ë¡œê·¸ ì •ì±…ìƒ ê³¼ë„í•œ ë°œí–‰ì€ ìŠ¤íŒ¸ìœ¼ë¡œ "
            "ë¶„ë¥˜ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ë°˜ë“œì‹œ ë§ˆì§€ë§‰ í¬ìŠ¤íŒ…ìœ¼ë¡œë¶€í„° 3ì‹œê°„ ê²½ê³¼ í›„ ë°œí–‰í•´ ì£¼ì„¸ìš”"
        )
    if can_regenerate:
        message += f"\n\nğŸ’¡ ë§ˆìŒì— ë“¤ì§€ ì•Šìœ¼ì‹œë©´ ì¬ìƒì„±ì„ {max_attempts - attempts_after}íšŒ ë” í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤."

    return {
        "success": True,
        "message": message,
        "dailyLimitWarning": daily_limit_warning,
        "drafts": draft_data,
        "sessionId": session.get("sessionId"),
        "attempts": attempts_after,
        "maxAttempts": max_attempts,
        "canRegenerate": can_regenerate,
        "metadata": {
            "generatedAt": generated_at,
            "userId": uid,
            "processingTime": started_ms,
            "multiAgent": {
                "enabled": True,
                "pipeline": "python-step-functions",
                "compliancePassed": compliance_passed,
                "complianceIssues": 0,
                "seoPassed": seo_passed,
                "keywords": pipeline_result.get("keywords") or user_keywords,
                "keywordValidation": keyword_validation or None,
                "duration": None,
                "partial": bool(pipeline_result.get("partial") is True),
                "partialReason": pipeline_result.get("partialReason"),
                "timeoutMs": None,
                "agentsCompleted": pipeline_result.get("agentsCompleted") or [],
                "lastAgent": pipeline_result.get("lastAgent"),
                "appliedStrategy": writing_method,
                "keywordCounts": keyword_counts,
                "wordCount": word_count,
            },
            "seo": {
                "passed": seo_passed,
                "keywordValidation": keyword_validation or None,
            },
            "highQuality": {"enabled": False},
        },
    }


def handle_generate_posts(req: https_fn.CallableRequest) -> Dict[str, Any]:
    progress: Optional[ProgressTracker] = None
    try:
        data = req.data if isinstance(req.data, dict) else {}
        if isinstance(data.get("data"), dict):
            data = data["data"]
        uid = req.auth.uid if req.auth else ""
        progress_session_id = str(data.get("progressSessionId") or f"{uid}_{int(time.time() * 1000)}")
        progress = ProgressTracker(progress_session_id)
        return handle_generate_posts_call(req)
    except ApiError as exc:
        logger.warning("generatePosts ì²˜ë¦¬ ì‹¤íŒ¨(ApiError): %s", exc)
        if progress:
            progress.error(str(exc))
        raise https_fn.HttpsError(exc.code, str(exc)) from exc
    except Exception as exc:
        logger.exception("generatePosts ì²˜ë¦¬ ì‹¤íŒ¨")
        if progress:
            progress.error(str(exc))
        raise https_fn.HttpsError("internal", f"ì›ê³  ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {exc}") from exc
