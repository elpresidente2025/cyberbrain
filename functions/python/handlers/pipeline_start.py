# handlers/pipeline_start.py
"""
Pipeline Start Handler - POST /pipeline/start

íŒŒì´í”„ë¼ì¸ì„ ì‹œì‘í•˜ê³  job_idë¥¼ ë°œê¸‰í•©ë‹ˆë‹¤.
ì²« ë²ˆì§¸ ë‹¨ê³„ë¥¼ Cloud Tasksë¡œ íŠ¸ë¦¬ê±°í•©ë‹ˆë‹¤.
"""

import json
import logging
from firebase_functions import https_fn

logger = logging.getLogger(__name__)


def handle_start(req: https_fn.Request) -> https_fn.Response:
    """
    íŒŒì´í”„ë¼ì¸ ì‹œì‘ - job_id ë°œê¸‰ ë° ì²« ë‹¨ê³„ íŠ¸ë¦¬ê±°
    
    Request Body:
        {
            "topic": "ì£¼ì œ (í•„ìˆ˜)",
            "category": "activity-report",
            "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2"],
            "user": { ... },
            "instructions": "...",
            "newsContext": "...",
            "pipeline": "modular"
        }
    
    Response (202 Accepted):
        {
            "success": true,
            "jobId": "uuid",
            "status": "running",
            "message": "..."
        }
    """

    try:
        # Lazy imports for faster cold start
        import asyncio
        from services.job_manager import JobManager
        from services.task_trigger import create_step_task
        from services.news_fetcher import fetch_naver_news, compress_news_with_ai, format_news_for_prompt, should_fetch_news
        # RAG & Style
        from rag_manager import LightRAGManager
        from agents.common.style_analyzer import extract_style_from_text
        from agents.common.gemini_client import get_client

        data = req.get_json(silent=True) or {}
        
        # ì…ë ¥ ê²€ì¦
        topic = data.get("topic")
        if not topic:
            return https_fn.Response(
                json.dumps({"error": "topic is required", "code": "INVALID_INPUT"}),
                status=400,
                mimetype="application/json"
            )

        # ğŸ›¡ï¸ [Security] ê¶Œí•œ ë° ì‚¬ìš©ëŸ‰ ì²´í¬
        # Node.js: checkGenerationPermission(uid)
        uid = data.get("uid") or user_profile.get("uid")
        if not uid:
             return https_fn.Response(
                json.dumps({"error": "User ID is required", "code": "UNAUTHENTICATED"}),
                status=401,
                mimetype="application/json"
            )
            
        try:
            from firebase_admin import firestore
            from services.access_control import check_generation_permission
            
            db = firestore.client()
            perm_result = check_generation_permission(uid, db)
            
            if not perm_result["allowed"]:
                return https_fn.Response(
                    json.dumps({
                        "error": perm_result.get("message", "ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤."),
                        "code": "PERMISSION_DENIED",
                        "reason": perm_result.get("reason"),
                        "suggestion": perm_result.get("suggestion")
                    }),
                    status=403,
                    mimetype="application/json"
                )
                
            logger.info(f"âœ… Permission granted for {uid}: {perm_result['reason']} (remaining: {perm_result.get('remaining', 'N/A')})")
            
        except Exception as e:
            logger.error(f"Permission check error: {e}")
            return https_fn.Response(
                json.dumps({"error": "ê¶Œí•œ í™•ì¸ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", "code": "INTERNAL_ERROR"}),
                status=500,
                mimetype="application/json"
            )

        category = data.get("category", "activity-report")
        user_profile = data.get("user", {})

        # --- Async Context Preparation Helper ---
        async def prepare_additional_context():
            results = {
                "newsContext": data.get("newsContext", ""),
                "ragContext": "",
                "styleHints": {}, # style_analyzer output
            }
            
            tasks = []
            
            # 1. News Fetching
            # ì´ë¯¸ newsContextê°€ ìˆê±°ë‚˜, newsDataText(ì‚¬ìš©ì ì…ë ¥)ê°€ ìˆìœ¼ë©´ ìŠ¤í‚µí•  ìˆ˜ë„ ìˆìŒ
            # í•˜ì§€ë§Œ Node.js ë¡œì§ì— ë”°ë¼ shouldFetchNewsê°€ trueì´ë©´ ê°€ì ¸ì˜¤ëŠ” ê²ƒì´ ì¼ë°˜ì 
            # ì—¬ê¸°ì„  newsContextê°€ ì—†ì„ ë•Œë§Œ ê°€ì ¸ì˜¤ë„ë¡ ì„¤ì •
            if not results["newsContext"] and should_fetch_news(category):
                async def fetch_news_task():
                    try:
                        # topicì´ ì—†ìœ¼ë©´ ë‰´ìŠ¤ ê²€ìƒ‰ ë¶ˆê°€
                        if not topic: return ""
                        news_items = await fetch_naver_news(topic) # Changed from fetch_news to fetch_naver_news to match original import
                        if news_items:
                            return await compress_news_with_ai(news_items)
                    except Exception as e:
                        logger.error(f"News fetch error: {e}")
                    return ""
                tasks.append(asyncio.create_task(fetch_news_task()))
                
            # 2. Style Analysis
            bio = user_profile.get("bio", "")
            if bio and len(bio) > 50:
                async def style_task():
                    try:
                        # ê°„ë‹¨í•œ ìŠ¤íƒ€ì¼ ë¶„ì„ ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œë¡œëŠ” style_analyzer.py ì‚¬ìš©)
                        from services.style_analyzer import analyze_style_from_bio
                        return await analyze_style_from_bio(bio)
                    except Exception as e:
                        logger.error(f"Style analysis error: {e}")
                        return {}
                tasks.append(asyncio.create_task(style_task()))

            # 3. Topic Classification (Auto)
            if category in ["auto", "general", "activity-report"] and topic:
                async def classify_task():
                    try:
                        from services.topic_classifier import classify_topic
                        result = await classify_topic(topic)
                        return result.get("writingMethod")
                    except Exception as e:
                        logger.error(f"Topic classification error: {e}")
                        return None
                tasks.append(asyncio.create_task(classify_task()))
                
            if not tasks: return results
            
            # Wait for all tasks
            done_results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # Map results back (ìˆœì„œ ì¤‘ìš”: News -> Style -> Classify)
            task_index = 0
            
            if not results["newsContext"] and should_fetch_news(category):
                if not isinstance(done_results[task_index], Exception):
                    results["newsContext"] = done_results[task_index]
                task_index += 1
                
            if bio and len(bio) > 50:
                if not isinstance(done_results[task_index], Exception):
                    results["styleHints"] = done_results[task_index]
                task_index += 1
                
            if category in ["auto", "general", "activity-report"] and topic:
                if not isinstance(done_results[task_index], Exception) and done_results[task_index]:
                    results["classifiedCategory"] = done_results[task_index]
                task_index += 1

            return results

        # Run Async Preparation (News, RAG, Style, Auto-Classification)
        try:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            additional_context = loop.run_until_complete(prepare_additional_context(topic, category, user_profile, data))
            loop.close()
        except Exception as e:
            logger.error(f"Context preparation failed: {e}")
            additional_context = {}
        
        # ì£¼ì œ ë¶„ë¥˜ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì¹´í…Œê³ ë¦¬ ì—…ë°ì´íŠ¸
        if additional_context.get("classifiedCategory"):
            category = additional_context["classifiedCategory"]
            logger.info(f"ğŸ¤– Category auto-classified to: {category}")
            
        context = {
            "topic": topic,
            "category": category,
            "keywords": data.get("keywords", []),
            "userProfile": user_profile,
            "newsContext": additional_context.get("newsContext", ""),
            "ragContext": additional_context.get("ragContext", ""),
            "styleHints": additional_context.get("styleHints", {}),
            "styleFingerprint": additional_context.get("styleFingerprint", {}),
        }

        # ì…ë ¥ ë°ì´í„° êµ¬ì„±
        input_data = {
            "topic": topic,
            "category": category,
            "keywords": data.get("keywords", []),
            "userProfile": user_profile,
            "instructions": data.get("instructions", ""),
            "stanceText": data.get("stanceText", ""),      # ğŸ”‘ [NEW] ì…ì¥ë¬¸ (ì‹¬ì¸µ ì£¼ì œ)
            "newsDataText": data.get("newsDataText", ""),  # ğŸ”‘ [NEW] ì‚¬ìš©ì ì œê³µ ë‰´ìŠ¤/ë°ì´í„°
            "newsContext": additional_context.get("newsContext", data.get("newsContext", "")),
            "styleHints": additional_context.get("styleHints", {}), # ğŸ”‘ [NEW] ìŠ¤íƒ€ì¼ ë¶„ì„ ê²°ê³¼
            "ragContext": additional_context.get("ragContext", ""), # ğŸ”‘ [NEW] RAG ê²°ê³¼
            "background": data.get("background", ""),
            "references": data.get("references", []),
            "targetWordCount": data.get("targetWordCount", 2000),
        }
        
        pipeline = data.get("pipeline", "modular")
        
        logger.info(f"Starting pipeline '{pipeline}' for topic: {topic[:50]}...")
        
        # Job ìƒì„±
        job_manager = JobManager()
        job_id = job_manager.create_job(input_data, pipeline)
        
        # ì²« ë²ˆì§¸ ë‹¨ê³„ íŠ¸ë¦¬ê±° (Cloud Tasks)
        task_name = create_step_task(job_id, step_index=0)
        logger.info(f"Triggered first step for job {job_id}: {task_name}")
        
        return https_fn.Response(
            json.dumps({
                "success": True,
                "jobId": job_id,
                "status": "running",
                "message": "íŒŒì´í”„ë¼ì¸ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤."
            }),
            status=202,  # Accepted
            mimetype="application/json"
        )
        
    except Exception as e:
        import traceback
        logger.error(f"Pipeline start failed: {e}")
        traceback.print_exc()
        
        return https_fn.Response(
            json.dumps({
                "error": str(e),
                "code": "INTERNAL_ERROR"
            }),
            status=500,
            mimetype="application/json"
        )
